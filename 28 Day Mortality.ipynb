{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77292963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from coxph_fitter import CoxPHFitter\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "import lifelines\n",
    "import pickle\n",
    "import copy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rs = 42\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e90eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_threshold = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4af23723",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a22588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(data):\n",
    "    cols = list(data)\n",
    "    for col in cols:\n",
    "        min_value = data[col].quantile(0.01)\n",
    "        max_value = data[col].quantile(0.99)\n",
    "        data[col][data[col] < min_value] = None\n",
    "        data[col][data[col] > max_value] = None\n",
    "    return data\n",
    "\n",
    "def quantize_bmi(cell):\n",
    "    if cell < 18.5:\n",
    "        return 0\n",
    "    elif cell <= 24.9:\n",
    "        return 1\n",
    "    elif cell <= 29.9:\n",
    "        return 2\n",
    "    elif cell <= 34.9:\n",
    "        return 3\n",
    "    elif cell <= 39:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "def get_status(cell):\n",
    "    if cell == 'DIED':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def cal_weights(event, logits_treatment, stabilized=True, clip = True):\n",
    "    ones_idx, zeros_idx = np.where(event == 1), np.where(event == 0)\n",
    "    p_T = len(ones_idx[0]) / (len(ones_idx[0]) + len(zeros_idx[0]))\n",
    "    if stabilized:\n",
    "        # stabilized weights:   treated_w.sum() + controlled_w.sum() ~ N\n",
    "        treated_w, controlled_w = p_T / logits_treatment[ones_idx], (1 - p_T) / (1. - logits_treatment[zeros_idx])\n",
    "    else:\n",
    "        # standard IPTW:  treated_w.sum() + controlled_w.sum() > N\n",
    "        treated_w, controlled_w = 1. / logits_treatment[ones_idx], 1. / (1. - logits_treatment[zeros_idx])\n",
    "\n",
    "    if clip:\n",
    "        # treated_w = np.clip(treated_w, a_min=1e-06, a_max=100)\n",
    "        # controlled_w = np.clip(controlled_w, a_min=1e-06, a_max=100)\n",
    "        amin = np.quantile(np.concatenate((treated_w, controlled_w)), 0.01)\n",
    "        amax = np.quantile(np.concatenate((treated_w, controlled_w)), 0.99)\n",
    "        print('Using IPTW trim [{}, {}]'.format(amin, amax))\n",
    "        treated_w = np.clip(treated_w, a_min=amin, a_max=amax)\n",
    "        controlled_w = np.clip(controlled_w, a_min=amin, a_max=amax)\n",
    "\n",
    "    treated_w, controlled_w = np.reshape(treated_w, (len(treated_w), 1)), np.reshape(controlled_w,\n",
    "                                                                                     (len(controlled_w), 1))\n",
    "    return treated_w, controlled_w\n",
    "\n",
    "\n",
    "def get_day(cell):\n",
    "    if cell == np.inf:\n",
    "        return cell\n",
    "    return int(cell[4:])\n",
    "\n",
    "def get_window_lists(cell):\n",
    "    day = get_day(cell)\n",
    "    l = []\n",
    "    for i in range(0, day+1):\n",
    "        l.append('day_' + str(i))\n",
    "    return l  \n",
    "\n",
    "def get_window_lists_adj(cell, no_censor_window=None):\n",
    "    day = get_day(cell)\n",
    "    l = []\n",
    "    for i in range(0, day+1+no_censor_window):\n",
    "        if i < 29: # only 28 days available\n",
    "            l.append('day_' + str(i))\n",
    "    return l  \n",
    "\n",
    "def check_balance_before_IPTW(X, all_vars):\n",
    "    feature_treatment = X[X['T'] == 1][all_vars]\n",
    "    feature_control = X[X['T'] == 0][all_vars]\n",
    "\n",
    "    treatment_mean = feature_treatment.mean(0)\n",
    "    treatment_std = feature_treatment.std(0)\n",
    "\n",
    "    control_mean = feature_control.mean(0)\n",
    "    control_std = feature_control.std(0)\n",
    "\n",
    "    SMD = np.abs(treatment_mean-control_mean) / np.sqrt((treatment_std**2 + control_std**2)/2)\n",
    "\n",
    "    print('Number of unbalanced covariates: ' + str((SMD>smd_threshold).sum()))\n",
    "\n",
    "    return SMD\n",
    "\n",
    "\n",
    "def check_balance_after_matching(X, all_vars):\n",
    "    feature_treatment = X[X['T'] == 1][all_vars]\n",
    "    feature_control = X[X['T'] == 0][all_vars]\n",
    "\n",
    "    treatment_mean = feature_treatment.mean(0)\n",
    "    treatment_std = feature_treatment.std(0)\n",
    "\n",
    "    control_mean = feature_control.mean(0)\n",
    "    control_std = feature_control.std(0)\n",
    "\n",
    "    SMD = np.abs(treatment_mean-control_mean) / np.sqrt((treatment_std**2 + control_std**2)/2)\n",
    "\n",
    "    return SMD\n",
    "\n",
    "def check_balance_after_IPTW(X, all_vars):\n",
    "    feature_treatment = X[X['T'] == 1][all_vars]\n",
    "    feature_control = X[X['T'] == 0][all_vars]\n",
    "\n",
    "    cohort_treatment = X[X['T'] == 1]['weight']\n",
    "    cohort_control = X[X['T'] == 0]['weight']\n",
    "\n",
    "    weight = np.array(cohort_treatment.values)\n",
    "    weight_sum = (weight).sum()\n",
    "    weight_2_sum = (weight ** 2).sum()\n",
    "\n",
    "    treatment_mean = (feature_treatment * weight[:,np.newaxis]).sum(0) / weight_sum\n",
    "    treatment_std = np.sqrt((weight_sum) / (weight_sum ** 2 - weight_2_sum) * (weight[:, np.newaxis] * ((feature_treatment - treatment_mean[np.newaxis,:]) ** 2)).sum(0))\n",
    "\n",
    "    weight = np.array(cohort_control.values)\n",
    "    weight_sum = (weight).sum()\n",
    "    weight_2_sum = (weight ** 2).sum()\n",
    "\n",
    "    control_mean = (feature_control * weight[:, np.newaxis]).sum(0) / weight_sum\n",
    "    control_std = np.sqrt((weight_sum) / (weight_sum ** 2 - weight_2_sum) * (weight[:, np.newaxis] * ((feature_control - control_mean[np.newaxis, :]) ** 2)).sum(0))\n",
    "\n",
    "    SMD = np.abs(treatment_mean-control_mean) / np.sqrt((treatment_std**2 + control_std**2)/2)\n",
    "\n",
    "    print('Number of unbalanced covariates: ' + str((SMD>smd_threshold).sum()))\n",
    "    return SMD\n",
    "\n",
    "\n",
    "def run_ps(df, X, T, Y):\n",
    "    # estimate the propensity score\n",
    "    temp = df.copy(deep=True)\n",
    "    ps = LogisticRegression().fit(temp[X], temp[T]).predict_proba(temp[X])[:, 1]\n",
    "    treated_w, controlled_w = cal_weights(temp[T].values, ps, stabilized=False)\n",
    "    ones_idx, zeros_idx = np.where(temp[T].values == 1), np.where(temp[T].values == 0)\n",
    "    weight = np.zeros(len(temp[T].values))\n",
    "    weight[ones_idx] = treated_w.squeeze()\n",
    "    weight[zeros_idx] = controlled_w.squeeze()\n",
    "    temp['weight'] = weight\n",
    "    treatment_effect = sum(temp.query(\"T==1\")[Y]*temp.query(\"T==1\")[\"weight\"]) / len(temp)\n",
    "    no_treatment_effect = sum(temp.query(\"T==0\")[Y]*temp.query(\"T==0\")[\"weight\"]) / len(temp)\n",
    "    return [treatment_effect, no_treatment_effect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching Iteratively\n",
    "\n",
    "# Utility to define caliper for Mahalanobis distance\n",
    "# median absolute deviation (MAD) of the calculated distances\n",
    "def mad(arr):\n",
    "    med = np.median(arr)\n",
    "    return np.median(np.abs(arr - med))\n",
    "\n",
    "def calculate_propensity_scores(X, treatment_col, covariate_list):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X[covariate_list], X[treatment_col])\n",
    "    propensity_scores = model.predict_proba(X[covariate_list])[:, 1]\n",
    "    X['ps'] = propensity_scores\n",
    "    return X\n",
    "\n",
    "def match_pairs(distances, treated_idx, control_idx, N=1, caliper=None):\n",
    "    matched_pairs = []\n",
    "    control_pool = copy.deepcopy(control_idx)\n",
    "    distance_pool = copy.deepcopy(distances)\n",
    "    matches_per_treated = dict.fromkeys(treated_idx, 0)\n",
    "    unmatchable = set()\n",
    "    while len(control_pool) > 0:\n",
    "        for i, treated in enumerate(treated_idx):\n",
    "            if treated in unmatchable or matches_per_treated[treated] >= N:\n",
    "                continue\n",
    "            if control_pool.empty:\n",
    "                break\n",
    "            min_index = np.argmin(distance_pool[i])\n",
    "            min_distance = distance_pool[i, min_index]\n",
    "            if caliper is not None and min_distance > caliper:\n",
    "                unmatchable.add(treated)\n",
    "                continue\n",
    "            matched_control = control_pool[min_index]\n",
    "            matched_pairs.append((treated, matched_control))\n",
    "            matches_per_treated[treated] += 1\n",
    "            control_pool = control_pool.drop(matched_control)\n",
    "            distance_pool = np.delete(distance_pool, min_index, axis=1)\n",
    "        if min(val for key, val in matches_per_treated.items() if key not in unmatchable) >= N:\n",
    "            break\n",
    "    return matched_pairs\n",
    "\n",
    "def iterative_matching(X, unbalanced_covariates, treatment_col, method='propensity', allow_repetition=False, use_caliper=False):\n",
    "    treated_idx = X[X[treatment_col] == 1].index\n",
    "    control_idx = X[X[treatment_col] == 0].index\n",
    "    running_data = X.copy(deep=True)\n",
    "    matched_pairs = []\n",
    "    for i, covariate in enumerate(unbalanced_covariates):\n",
    "        multiplier = 1\n",
    "        if i == 0:\n",
    "            distances = calculate_distance(running_data, treated_idx, control_idx, covariate, treatment_col, method)\n",
    "            if (covariate in continuous_vars) and use_caliper:\n",
    "                flat_distances = distances.flatten()\n",
    "                caliper = multiplier * mad(flat_distances)\n",
    "            else:\n",
    "                caliper = None\n",
    "            pairs = match_pairs(distances, treated_idx, control_idx, allow_repetition=allow_repetition, caliper=caliper)\n",
    "            matched_pairs = pairs\n",
    "        else:\n",
    "            matched_indices = [idx for pair in matched_pairs for idx in pair]\n",
    "            running_data = running_data.loc[matched_indices]\n",
    "            treated_idx = running_data[running_data[treatment_col] == 1].index\n",
    "            control_idx = running_data[running_data[treatment_col] == 0].index\n",
    "            distances = calculate_distance(running_data, treated_idx, control_idx, covariate, treatment_col, method)\n",
    "            if (covariate in continuous_vars) and use_caliper:\n",
    "                flat_distances = distances.flatten()\n",
    "                caliper = multiplier * mad(flat_distances)\n",
    "            else:\n",
    "                caliper = None\n",
    "            pairs = match_pairs(distances, treated_idx, control_idx, allow_repetition=allow_repetition, caliper=caliper)\n",
    "            matched_pairs = pairs\n",
    "    return matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a195f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_propensity(X, treated_idx, control_idx, covariates, treatment_col):\n",
    "    X_ps = calculate_propensity_scores(X, treatment_col, covariates)\n",
    "    treated_data = X_ps.loc[treated_idx, 'ps'].values.reshape(-1, 1)\n",
    "    control_data = X_ps.loc[control_idx, 'ps'].values.reshape(-1, 1)\n",
    "    distances = distance.cdist(treated_data, control_data, metric='mahalanobis')\n",
    "    return distances, X_ps\n",
    "\n",
    "\n",
    "def matching_propensity(X, unbalanced_covariates, treatment_col, N=1, allow_repetition=False, use_caliper=False):\n",
    "    treated_idx = X[X[treatment_col] == 1].index\n",
    "    control_idx = X[X[treatment_col] == 0].index\n",
    "    running_data = X.copy(deep=True)\n",
    "    matched_pairs = []\n",
    "    multiplier = 1\n",
    "    distances, X_ps = calculate_distance_propensity(running_data, treated_idx, control_idx, unbalanced_covariates, treatment_col)\n",
    "    flat_distances = distances.flatten()\n",
    "    caliper = multiplier * mad(flat_distances)\n",
    "    pairs = match_pairs(distances, treated_idx, control_idx, N=N, caliper=caliper)\n",
    "    matched_pairs = pairs\n",
    "    return matched_pairs, X_ps\n",
    "\n",
    "\n",
    "def perform_balancing_method3(X, imp_covariates, all_vars, use_caliper=True):\n",
    "    treatment_col = 'T'\n",
    "    # Matching Based on Propensity Scores\n",
    "    balances = check_balance_after_matching(X, all_vars)\n",
    "    # loop through a couple range 0 - 0.1 in interval 0.025\n",
    "    Ns = [1, 2, 3]\n",
    "    Ns = [4]\n",
    "    for N in Ns:\n",
    "        threshs = [0, 0.025, 0.05, 0.075, 0.1]\n",
    "        threshs = [0]\n",
    "        thresh_dict = dict.fromkeys(threshs)\n",
    "        for thresh in threshs:\n",
    "            thresh_dict[thresh] = {}\n",
    "            balances_tuples = balances[balances > thresh]\n",
    "            unbalanced_covariates = list(balances_tuples.sort_values(ascending=False).index)\n",
    "            matched_pairs, X_ps = matching_propensity(X, unbalanced_covariates, treatment_col, N=N, use_caliper=use_caliper)\n",
    "            matched_indices = [idx for pair in matched_pairs for idx in pair]\n",
    "            X_matched = X_ps.loc[matched_indices].reset_index(drop=True)\n",
    "            new_balances = check_balance_after_matching(X_matched, all_vars)\n",
    "            new_balances_tuples = new_balances[new_balances > smd_threshold]\n",
    "            new_unbalanced_covariates = list(new_balances_tuples.sort_values(ascending=False).index)\n",
    "            thresh_dict[thresh]['data'] = X_matched\n",
    "            thresh_dict[thresh]['unbalanced_covars'] = new_unbalanced_covariates\n",
    "            if len(new_unbalanced_covariates) == 0:\n",
    "                print(f\"Using Threshold of {thresh}, Using N of {N}\")\n",
    "                return X_matched\n",
    "                break\n",
    "    min_key, items = min(thresh_dict.items(), key=lambda x: len(x[1]['unbalanced_covars']))\n",
    "    print(f\"Using Threshold of {min_key}, Using N of {N}\")\n",
    "    return items['data']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30f2670d",
   "metadata": {},
   "source": [
    "#### eICU Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steriods_eicu = pd.read_csv(\"data/eICU/steroids.csv\")\n",
    "df_steriods_eicu['patientunitstayid'] = df_steriods_eicu['patientunitstayid'].astype(int)\n",
    "df_features_eicu = pd.read_csv(\"data/eICU/feature.csv\")\n",
    "df_patient_eicu = pd.read_csv(\"data/eICU/eicu-database-2.0/patient.csv\")\n",
    "df_sepsis_eicu = pd.read_csv(\"data/eICU/sepsis.csv\")\n",
    "\n",
    "df_comorb_eicu = pd.read_csv(\"data/eICU/patient_comorbidity_score_df.csv\")\n",
    "df_sofa_eicu = pd.read_csv(\"data/eICU/eICU_sofa.csv\")\n",
    "df_sofa_comps_eicu = pd.read_csv(\"data/eICU/eICU_SOFA_score_comps.csv\")\n",
    "\n",
    "df_features_eicu = pd.merge(df_features_eicu, df_comorb_eicu[['patientunitstayid', 'comorbidity_score']], on='patientunitstayid',\n",
    "                       how='left')\n",
    "df_features_eicu = pd.merge(df_features_eicu, df_sofa_eicu[['patientunitstayid', 'sofa']], on='patientunitstayid',\n",
    "                       how='left')\n",
    "df_features_eicu = pd.merge(df_features_eicu, df_sofa_comps_eicu, on='patientunitstayid',\n",
    "                       how='left')\n",
    "sofa_comps = ['Respiration_score', 'Cardiovascular_score', 'CNS_score', 'Liver_score', 'Coagulation_score', 'Renal_score']\n",
    "df_features_eicu[sofa_comps] = df_features_eicu[sofa_comps].fillna(0)\n",
    "df_features_eicu['sofa'] = df_features_eicu['Respiration_score'] + \\\n",
    "                            df_features_eicu['Coagulation_score'] + \\\n",
    "                            df_features_eicu['Liver_score'] + \\\n",
    "                            df_features_eicu['Cardiovascular_score'] + \\\n",
    "                            df_features_eicu['CNS_score'] + \\\n",
    "                            df_features_eicu['Renal_score']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e794e27",
   "metadata": {},
   "source": [
    "#### MIMIC Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steriods_mim = pd.read_csv(\"data/MIMIC/steroids.csv\")\n",
    "df_steriods_mim['patientunitstayid'] = df_steriods_mim['patientunitstayid'].astype(int)\n",
    "df_patient_mim = pd.read_csv(\"data/MIMIC/patient_info.csv\")\n",
    "df_patient_mim.rename(columns={'stay_id':'patientunitstayid'}, inplace=True)\n",
    "df_sepsis_mim = pd.read_csv(\"data/MIMIC/sepsis_sofa.csv\")\n",
    "df_sepsis_mim.rename(columns={'icustay_id':'patientunitstayid'}, inplace=True)\n",
    "\n",
    "df_comorb_mim = pd.read_csv(\"data/MIMIC/patient_comorbidity_score_df.csv\")\n",
    "df_sofa_comps_mim = pd.read_csv(\"data/MIMIC/sofa_score_comps.csv\")\n",
    "\n",
    "df_features_mim = pd.read_csv(\"data/MIMIC/features.csv\")\n",
    "df_comorb_mim = pd.merge(df_patient_mim[['subject_id', 'patientunitstayid']], df_comorb_mim, on='subject_id',\n",
    "                       how='left')\n",
    "df_features_mim = pd.merge(df_features_mim, df_comorb_mim[['patientunitstayid', 'comorbidity_score']], on='patientunitstayid',\n",
    "                       how='left')\n",
    "df_features_mim = pd.merge(df_features_mim, df_sofa_comps_mim, on='patientunitstayid',\n",
    "                       how='left')\n",
    "df_features_mim.rename(columns={'SOFA_score':'sofa'}, inplace=True)\n",
    "df_features_mim = pd.merge(df_features_mim, df_patient_mim[['patientunitstayid', 'gender', 'age']], on='patientunitstayid',\n",
    "                       how='left')\n",
    "sofa_comps = ['Respiration_score', 'Cardiovascular_score', 'CNS_score', 'Liver_score', 'Coagulation_score', 'Renal_score']\n",
    "df_features_mim[sofa_comps] = df_features_mim[sofa_comps].fillna(0)\n",
    "df_features_mim['sofa'] = df_features_mim['Respiration_score'] + \\\n",
    "                            df_features_mim['Coagulation_score'] + \\\n",
    "                            df_features_mim['Liver_score'] + \\\n",
    "                            df_features_mim['Cardiovascular_score'] + \\\n",
    "                            df_features_mim['CNS_score'] + \\\n",
    "                            df_features_mim['Renal_score']\n",
    "\n",
    "# Imputing Height and Weight\n",
    "imputer = IterativeImputer(random_state=100, max_iter=10)\n",
    "df_train = df_features_mim.loc[:, [\"Height\", \"Weight\"]]\n",
    "imputer.fit(df_train)\n",
    "df_imputed = imputer.transform(df_train)\n",
    "df_features_mim[['Height', 'Weight']] = df_imputed\n",
    "df_features_mim['Height'] = df_features_mim['Height'].apply(lambda x: x if x >= 48 else 48)\n",
    "# height is in inches, weight is in kg\n",
    "df_features_mim['BMI'] = ((df_features_mim['Weight'] * 2.20462) / (df_features_mim['Height']*df_features_mim['Height']) * 703).astype(int)\n",
    "max_days = 28\n",
    "\n",
    "# Making GCS Feature\n",
    "for i in range(1, max_days+1):\n",
    "    df_features_mim[f'GCS_day_{i}'] = df_features_mim[f'gcsVerbal_day_{i}'] + df_features_mim[f'gcsMotor_day_{i}'] + df_features_mim[f'gcsEye_day_{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zx_subtypes_eicu = pd.read_csv(\"data/eICU/zxu_subtypes_lr_24h.csv\")\n",
    "df_zx_subtypes_mim = pd.read_csv(\"data/MIMIC/zxu_subtypes_lr_24h.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13b8bb31",
   "metadata": {},
   "source": [
    "#### Eligibility Criteria Filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2209c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subcomponent Analysis\n",
    "sub_component_analysis = 0\n",
    "cv = 1\n",
    "resp = 0\n",
    "cns = 0\n",
    "liv = 0\n",
    "coag = 0\n",
    "rn = 0\n",
    "greater = 1\n",
    "lesser = not greater\n",
    "\n",
    "sepsis_zx_subtype = 'NONE'\n",
    "# options include NONE, 1, 3 (others too small)\n",
    "\n",
    "# Default Parameters to Stick to\n",
    "extend_discharge_best_case = 1\n",
    "extend_other_best_case = 0\n",
    "treatment_strat_question = 1\n",
    "biological_question = not treatment_strat_question\n",
    "grace_period_hours = 0\n",
    "remove_event_before_grace = 0\n",
    "create_clones_before_grace_outcome = 1\n",
    "create_clones = grace_period_hours\n",
    "perform_censoring = 0 or (biological_question)\n",
    "remove_censored = 0\n",
    "include_extra_treated = 1\n",
    "remove_immortal_time_treated = 1\n",
    "remove_missing_feats = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d1325af",
   "metadata": {},
   "source": [
    "#### eICU Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45984b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_patients_eicu = df_sepsis_eicu[df_sepsis_eicu['sepsis_onset'] <= 1440]['patientunitstayid'].values\n",
    "\n",
    "# Get rid of patient with previous steriod usage to Day 0\n",
    "# Only if greater than 160\n",
    "steroid_dosage = 160\n",
    "df_st = df_steriods_eicu[df_steriods_eicu['day_0'] < steroid_dosage]\n",
    "\n",
    "# Get rid of patients without sepsis\n",
    "df_st = df_st[df_st['patientunitstayid'].isin(sepsis_patients_eicu)]\n",
    "\n",
    "df_censor = df_st.copy(deep=True)\n",
    "\n",
    "# Patient is treated if they have over 160 steriods within grace window from inclusion criteria\n",
    "grace_period_days = int(grace_period_hours/24.0)\n",
    "\n",
    "grace_days_consider = []\n",
    "for i in range(0, 2+grace_period_days):\n",
    "    grace_days_consider.append(f\"day_{i}\")\n",
    "\n",
    "if biological_question:\n",
    "    df_st_temp = df_st.copy(deep=True)\n",
    "    df_st_temp = df_st_temp.set_index('patientunitstayid')\n",
    "    df_st_temp['treatment_day']=df_st_temp.keys()[np.argmax(df_st_temp.values>=steroid_dosage,axis=1)]\n",
    "    patients_to_keep = df_st_temp['treatment_day'].isin(grace_days_consider)\n",
    "    df_st_temp = df_st_temp[patients_to_keep]\n",
    "    df_st = df_st[patients_to_keep.values]\n",
    "    df_censor = df_censor[patients_to_keep.values]\n",
    "elif treatment_strat_question:\n",
    "    df_st_temp = df_st.copy(deep=True)\n",
    "    df_st_temp = df_st_temp.set_index('patientunitstayid')\n",
    "    df_st_temp = df_st_temp[grace_days_consider]\n",
    "    df_st_temp['treatment_day']=df_st_temp.keys()[np.argmax(df_st_temp.values>=steroid_dosage,axis=1)]\n",
    "\n",
    "# If resultant is day_0, that means it is not eligible (no steroid > 160)\n",
    "df_st['T'] = (df_st_temp['treatment_day'] != 'day_0').values\n",
    "\n",
    "df_st['T'] = df_st['T'].astype(int)\n",
    "df_st['treatment_day'] = df_st_temp['treatment_day'].values\n",
    "df_censor['treatment_day'] = df_st_temp['treatment_day'].values\n",
    "\n",
    "no_censor_window = 3\n",
    "df_censor['window_days'] = df_censor['treatment_day'].apply(get_window_lists_adj, no_censor_window=no_censor_window)\n",
    "\n",
    "# Window where steriod admin is ok and if steriod admin after, patient is censored\n",
    "## Excluding last for coding purposes --> when deciding censoring, start at day after\n",
    "censor_days = []\n",
    "for i in df_censor['patientunitstayid'].values:\n",
    "    df_censor_temp = df_censor[df_censor['patientunitstayid'] == i]\n",
    "    window_days = df_censor_temp['window_days'].values[0]\n",
    "    treatment_day = df_censor_temp['treatment_day'].values[0]\n",
    "    df_censor_temp = df_censor_temp.drop(columns=window_days+['treatment_day', 'window_days', 'patientunitstayid'])\n",
    "    if df_censor_temp.size == 0:\n",
    "        censor_days.append(np.inf)\n",
    "        continue\n",
    "    else:\n",
    "        if np.sum(df_censor_temp.values>=steroid_dosage) == 0:\n",
    "            censor_days.append(np.inf)\n",
    "            continue\n",
    "        else:\n",
    "            censor_day = df_censor_temp.keys()[np.argmax(df_censor_temp.values>=steroid_dosage,axis=1)].values[0]\n",
    "    treated = df_st[df_st['patientunitstayid'] == i]['T'].values[0]\n",
    "    censor_days.append(censor_day)\n",
    "\n",
    "df_censor['censor'] = censor_days\n",
    "df_censor = df_censor.reset_index(drop=True)\n",
    "df_censor = df_censor[['patientunitstayid', 'censor']].reset_index(drop=True)\n",
    "\n",
    "df_st = pd.merge(df_st, df_censor, on='patientunitstayid')\n",
    "\n",
    "# Getting Mortality Information\n",
    "df_pat = df_patient_eicu[['patientunitstayid', 'hospitaldischargestatus', 'hospitaldischargeoffset', 'hospitaldischargelocation']]\n",
    "df_pat = df_pat.dropna(subset=['patientunitstayid', 'hospitaldischargestatus', 'hospitaldischargeoffset'])\n",
    "df_pat['hospitaldischargestatus'] = df_pat['hospitaldischargestatus'].astype('category').cat.codes\n",
    "df_pat['duration_day'] = df_pat['hospitaldischargeoffset'] / (60 * 24.0)\n",
    "\n",
    "# # Do we treat people who died after 28 days as alive? And set duration to 28 days?\n",
    "df_pat.loc[df_pat['duration_day'] >= 28, 'hospitaldischargestatus'] = 0\n",
    "df_pat.loc[df_pat['duration_day'] >= 28, 'duration_day'] = 28\n",
    "df_pat = df_pat[df_pat['duration_day'] >= 0]\n",
    "\n",
    "if remove_event_before_grace:\n",
    "    str_day = grace_days_consider[-1]\n",
    "    day = get_day(str_day)\n",
    "    df_pat = df_pat[df_pat['duration_day'] >= day]\n",
    "\n",
    "df_st_pat = pd.merge(df_st, df_pat, on='patientunitstayid')\n",
    "df_st_pat['treatment_day'] = df_st_pat['treatment_day'].apply(get_day)\n",
    "df_st_pat['censor'] = df_st_pat['censor'].apply(get_day)\n",
    "\n",
    "if create_clones_before_grace_outcome:\n",
    "    temp = df_st_pat[df_st_pat['duration_day'] < get_day(grace_days_consider[-1])]\n",
    "    # Make treated clones\n",
    "    df_untreated_to_treated = temp[temp['T'] == 0]\n",
    "    df_untreated_to_treated['T'] = 1\n",
    "    df_untreated_to_treated['treatment_day'] = 1\n",
    "    # df_untreated_to_treated['hospitaldischargestatus'] = 0 # censor these patients?\n",
    "    # Make untreated clones\n",
    "    df_treated_to_untreated = temp[temp['T'] == 1]\n",
    "    df_treated_to_untreated['T'] = 0\n",
    "    df_treated_to_untreated['treatment_day'] = 0\n",
    "    # df_treated_to_untreated['hospitaldischargestatus'] = 0 # censor these patients?\n",
    "    df_st_pat = pd.concat([df_st_pat, df_untreated_to_treated, df_treated_to_untreated]).reset_index(drop=True)\n",
    "\n",
    "# Figure out real duration with Day 0 based on treatment (steroid > 160)\n",
    "df_st_pat['temp_treatment_day'] = 0\n",
    "df_st_pat.loc[df_st_pat['treatment_day'] >= 1, 'temp_treatment_day'] = df_st_pat['treatment_day'] - 1\n",
    "df_st_pat['duration_real'] = df_st_pat['duration_day'] - df_st_pat['temp_treatment_day'] \n",
    "# Figure out duration if censoring for each patient\n",
    "df_st_pat['duration_censor'] = df_st_pat['censor'] - df_st_pat['treatment_day']\n",
    "# Some patients die on the day they are treated - treat their duration as 0\n",
    "df_st_pat[(df_st_pat['duration_real'] < 0) & (df_st_pat['duration_real'] > -1)] = 0\n",
    "# Small number of patients have duration much smaller than treatment - weird samples\n",
    "df_st_pat = df_st_pat[df_st_pat['duration_real'] > 0]\n",
    "\n",
    "if perform_censoring:\n",
    "    # Account for censoring in duration\n",
    "    df_st_pat['duration_final'] = df_st_pat[['duration_censor','duration_real']].min(axis=1)\n",
    "elif remove_censored:\n",
    "    # Remove patients who were censored due to retreatment\n",
    "    df_st_pat['duration_censor'] = df_st_pat['duration_censor'].replace(np.inf, 1000)\n",
    "    df_st_pat = df_st_pat[df_st_pat.duration_real <= df_st_pat.duration_censor]\n",
    "    df_st_pat['duration_final'] = df_st_pat['duration_real']\n",
    "else:\n",
    "    # Do not Account for censoring in duration\n",
    "    df_st_pat['duration_final'] = df_st_pat['duration_real']\n",
    "\n",
    "df_temp = df_st_pat.copy(deep=True)\n",
    "df_st_pat = df_st_pat[['patientunitstayid', 'T', 'hospitaldischargestatus', 'hospitaldischargelocation', 'duration_final', 'duration_real', 'duration_day', 'duration_censor', 'treatment_day']]\n",
    "df_st_pat = df_st_pat.reset_index(drop=True)\n",
    "\n",
    "# Other Categories are censored (set to 0 at duration)\n",
    "# Discarge events are extended to best case\n",
    "if extend_discharge_best_case:\n",
    "    if extend_other_best_case:\n",
    "        df_st_pat['hospitaldischargelocation_coded'] =  df_st_pat[\"hospitaldischargelocation\"].map({'Other External':1,\n",
    "                                            'Other Hospital':1, 'Skilled Nursing Facility':1,\n",
    "                                               'Home':1, 'Rehabilitation':1, 'Death':0,\n",
    "                                                        'Nursing Home':1, 'Other':1})\n",
    "    else:\n",
    "        df_st_pat['hospitaldischargelocation_coded'] =  df_st_pat[\"hospitaldischargelocation\"].map({'Other External':0,\n",
    "                                            'Other Hospital':0, 'Skilled Nursing Facility':1,\n",
    "                                               'Home':1, 'Rehabilitation':1, 'Death':0,\n",
    "                                                        'Nursing Home':1, 'Other':0})\n",
    "\n",
    "    # Best-Outcome Censoring for those that have discarge\n",
    "    df_st_pat.loc[df_st_pat[\"hospitaldischargelocation_coded\"] == 1, \"duration_final\"] = 28\n",
    "\n",
    "if sub_component_analysis:\n",
    "    df_st_pat = pd.merge(df_st_pat, df_sofa_comps_eicu, on='patientunitstayid')\n",
    "    if cv:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Cardiovascular_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Cardiovascular_score'] < 2]\n",
    "    elif resp:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Respiration_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Respiration_score'] < 2]\n",
    "    elif cns:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['CNS_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['CNS_score'] < 2]\n",
    "    elif liv:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Liver_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Liver_score'] < 2]\n",
    "    elif coag:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Coagulation_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Coagulation_score'] < 2]\n",
    "    elif rn:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Renal_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Renal_score'] < 2]\n",
    "    df_st_pat = df_st_pat.drop(columns=['Cardiovascular_score', 'Respiration_score', 'CNS_score', 'Liver_score', 'Coagulation_score', 'Renal_score'])\n",
    "    \n",
    "try:\n",
    "    zx_group = int(sepsis_zx_subtype)\n",
    "    subtype_patients = df_zx_subtypes_eicu[df_zx_subtypes_eicu['subtype'] == zx_group]['patientunitstayid'].values\n",
    "    df_st_pat = df_st_pat[df_st_pat['patientunitstayid'].isin(subtype_patients)]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_st_pat_eicu = df_st_pat.copy(deep=True)\n",
    "\n",
    "df_feat = df_features_eicu.copy(deep=True)\n",
    "df_feat = df_feat[df_feat['patientunitstayid'].isin(df_st_pat['patientunitstayid'].values)]\n",
    "feat_day_titles = [\"day_\" + str(i+1) for i in range(28)]\n",
    "\n",
    "df_feat_eicu_for_demo = df_feat.copy(deep=True)\n",
    "\n",
    "# Drop Extremely Missing Features\n",
    "lymph_features = ['Lymphocyte_count_' + day_title for day_title in feat_day_titles]\n",
    "df_feat.drop(columns=lymph_features, inplace=True)\n",
    "time_feature_names = ['Albumin', 'ALT', 'AST', 'Bands', 'Bicarbonate', 'Bilirubin',\n",
    "                 'BUN','Chloride', 'Creatinine', 'CRP', 'FiO2', 'GCS', 'Glucose', 'Heart_rate',\n",
    "                 'Hemoglobin', 'INR', 'Lactate', 'Lymphocyte_percent', 'MAP',\n",
    "                 'PaO2', 'Platelet', 'RDW', 'Respiratory_rate','SO2', 'Sodium','Systolic_ABP',\n",
    "                 'Temperature', 'Troponin I', 'Troponin T', 'Urine', 'WBC']\n",
    "baseline_feature_names = ['age', 'gender', 'BMI', 'comorbidity_score', 'sofa', 'Respiration_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score']\n",
    "\n",
    "# Missingness for Baseline Confounders\n",
    "imp_mean = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "df_feat.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "df_feat['gender'] = df_feat['gender'].fillna(\"Missing\")\n",
    "one_hot_gender = pd.get_dummies(df_feat['gender'])\n",
    "df_feat = df_feat.drop('gender',axis = 1)\n",
    "df_feat = df_feat.join(one_hot_gender)\n",
    "df_feat = df_feat.rename(columns={\"Female\": \"gender_Female\", \"Male\": \"gender_Male\",\n",
    "                                 \"Unknown\": \"gender_Unknown\"})\n",
    "if 'gender_Unknown' in df_feat:\n",
    "    df_feat['gender_Missing'] = df_feat['gender_Unknown']\n",
    "    df_feat.drop(columns=['gender_Unknown'], inplace=True)\n",
    "else:\n",
    "    df_feat['gender_Missing'] = 0\n",
    "\n",
    "num_vars = ['Albumin', 'ALT', 'AST', 'Bands', 'Bicarbonate',\n",
    "                     'Bilirubin', 'BUN', 'Chloride', 'Creatinine', 'CRP',\n",
    "                     'FiO2', 'GCS', 'Glucose', 'Heart_rate', 'Hemoglobin',\n",
    "                     'INR', 'Lactate', 'Lymphocyte_percent', 'MAP', 'PaO2',\n",
    "                     'Platelet', 'RDW', 'Respiratory_rate', 'SO2', 'Sodium',\n",
    "                     'Systolic_ABP', 'Temperature', 'Troponin I', 'Troponin T',\n",
    "                     'Urine', 'WBC']\n",
    "num_feats = ['age', 'BMI']\n",
    "for i in range(0, 28):\n",
    "    for var in num_vars:\n",
    "        num_feats.append(f\"{var}_day_{i+1}\")\n",
    "df_feat[num_feats] = clean_outliers(df_feat[num_feats])\n",
    "df_feat['age_missing'] = df_feat['age'].isnull().astype(int)\n",
    "df_feat['BMI_missing'] = df_feat['BMI'].isnull().astype(int)\n",
    "df_feat['age'] = imp_mean.fit_transform(df_feat['age'].values.reshape(-1,1))[:,0]\n",
    "df_feat['BMI'] = imp_mean.fit_transform(df_feat['BMI'].values.reshape(-1,1))[:,0]\n",
    "df_feat['sofa'] = imp_mean.fit_transform(df_feat['sofa'].values.reshape(-1,1))[:,0]\n",
    "\n",
    "# Quantizing BMI\n",
    "df_feat['BMI_quant'] = df_feat['BMI'].apply(quantize_bmi)\n",
    "df_feat['BMI_orig'] = df_feat['BMI']\n",
    "df_feat['BMI'] = df_feat['BMI_quant']\n",
    "\n",
    "# Quantizing Age\n",
    "df_feat['age_quant'], age_bins = pd.qcut(df_feat['age'], 5, labels=[0,1,2,3,4], retbins=True, precision=3, duplicates='raise')\n",
    "df_feat['age_orig'] = df_feat['age']\n",
    "df_feat['age'] = df_feat['age_quant']\n",
    "imp_median = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "df_feat['age'] = df_feat['age'].astype(float)\n",
    "df_feat['age'] = imp_median.fit_transform(df_feat['age'].values.reshape(-1,1))\n",
    "df_feat['age'] = df_feat['age'].astype(int)\n",
    "\n",
    "# Missingness for Time Varying Covariates\n",
    "for tv_feature in time_feature_names:\n",
    "    tv_feature_all = [tv_feature + '_' + day_title for day_title in feat_day_titles]\n",
    "    df_feat[tv_feature_all] = clean_outliers(df_feat[tv_feature_all])\n",
    "    df_feat[tv_feature_all] = df_feat[tv_feature_all].ffill(axis = 1)\n",
    "    df_feat[tv_feature_all] = imp_mean.fit_transform(df_feat[tv_feature_all])\n",
    "\n",
    "# Point Treatments (Get Day of Treatment for Treated) \n",
    "df_confounder_list = []\n",
    "base_features = ['age', 'gender_Male', 'gender_Missing', 'BMI', 'age_missing',\n",
    "                 'BMI_missing', 'comorbidity_score', 'sofa', 'Respiration_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score']\n",
    "col_titles = ['patientunitstayid'] + time_feature_names + base_features\n",
    "\n",
    "\n",
    "for pat, T in zip(df_st_pat['patientunitstayid'].values, df_st_pat['T'].values):\n",
    "    treatment_day = df_st_pat[(df_st_pat['patientunitstayid'] == pat) & (df_st_pat['T'] == T)]['treatment_day'].values[0]\n",
    "    if treatment_day == 0:\n",
    "        treatment_day = 1\n",
    "    tv_point_features = [feat + '_day_' + str(treatment_day) for feat in time_feature_names]\n",
    "    confounders =  tv_point_features + base_features\n",
    "    df_feat_temp = df_feat[df_feat['patientunitstayid'] == pat]\n",
    "    df_feat_temp = df_feat_temp[['patientunitstayid'] + confounders].reset_index(drop=True)\n",
    "    df_feat_temp.columns = col_titles\n",
    "    df_feat_temp['T'] = T\n",
    "    df_confounder_list.append(df_feat_temp)\n",
    "    \n",
    "df_confounders_eicu = pd.concat(df_confounder_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e00deeec",
   "metadata": {},
   "source": [
    "#### MIMIC Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42870295",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_patients_mim = df_sepsis_mim[df_sepsis_mim['hour_24'] >= 2]['patientunitstayid'].values\n",
    "\n",
    "# Get rid of patient with previous steriod usage to Day 0\n",
    "# Only if greater than 160\n",
    "steroid_dosage = 160\n",
    "df_st = df_steriods_mim[df_steriods_mim['day_-1'] < steroid_dosage]\n",
    "\n",
    "# Get rid of patients without sepsis\n",
    "df_st = df_st[df_st['patientunitstayid'].isin(sepsis_patients_mim)]\n",
    "df_st_follow_time = df_st[['patientunitstayid', 'follow-up-time']]\n",
    "df_st = df_st.drop(columns=['follow-up-time'])\n",
    "\n",
    "df_censor = df_st.copy(deep=True)\n",
    "\n",
    "# Patient is treated if they have over 160 steriods within grace window from inclusion criteria\n",
    "grace_period_days = int(grace_period_hours/24.0)\n",
    "\n",
    "grace_days_consider = []\n",
    "for i in range(0, 2+grace_period_days):\n",
    "    grace_days_consider.append(f\"day_{i}\")\n",
    "\n",
    "if biological_question:\n",
    "    df_st_temp = df_st.copy(deep=True)\n",
    "    df_st_temp = df_st_temp.set_index('patientunitstayid')\n",
    "    df_st_temp['treatment_day']=df_st_temp.keys()[np.argmax(df_st_temp.values>=steroid_dosage,axis=1)]\n",
    "    patients_to_keep = df_st_temp['treatment_day'].isin(grace_days_consider)\n",
    "    df_st_temp = df_st_temp[patients_to_keep]\n",
    "    df_st = df_st[patients_to_keep.values]\n",
    "    df_censor = df_censor[patients_to_keep.values]\n",
    "elif treatment_strat_question:\n",
    "    df_st_temp = df_st.copy(deep=True)\n",
    "    df_st_temp = df_st_temp.set_index('patientunitstayid')\n",
    "    df_st_temp = df_st_temp[grace_days_consider]\n",
    "    df_st_temp['treatment_day']=df_st_temp.keys()[np.argmax(df_st_temp.values>=steroid_dosage,axis=1)]\n",
    "\n",
    "# If resultant is day_0, that means it is not eligible (no steroid > 160)\n",
    "df_st['T'] = (df_st_temp['treatment_day'] != 'day_0').values\n",
    "\n",
    "df_st['T'] = df_st['T'].astype(int)\n",
    "df_st['treatment_day'] = df_st_temp['treatment_day'].values\n",
    "df_censor['treatment_day'] = df_st_temp['treatment_day'].values\n",
    "\n",
    "no_censor_window = 3\n",
    "df_censor['window_days'] = df_censor['treatment_day'].apply(get_window_lists_adj, no_censor_window=no_censor_window)\n",
    "\n",
    "# Window where steriod admin is ok and if steriod admin after, patient is censored\n",
    "## Excluding last for coding purposes --> when deciding censoring, start at day after\n",
    "censor_days = []\n",
    "for i in df_censor['patientunitstayid'].values:\n",
    "    df_censor_temp = df_censor[df_censor['patientunitstayid'] == i]\n",
    "    window_days = df_censor_temp['window_days'].values[0]\n",
    "    treatment_day = df_censor_temp['treatment_day'].values[0]\n",
    "    df_censor_temp = df_censor_temp.drop(columns=window_days+['treatment_day', 'window_days', 'patientunitstayid'])\n",
    "    if df_censor_temp.size == 0:\n",
    "        censor_days.append(np.inf)\n",
    "        continue\n",
    "    else:\n",
    "        if np.sum(df_censor_temp.values>=steroid_dosage) == 0:\n",
    "            censor_days.append(np.inf)\n",
    "            continue\n",
    "        else:\n",
    "            censor_day = df_censor_temp.keys()[np.argmax(df_censor_temp.values>=steroid_dosage,axis=1)].values[0]\n",
    "    treated = df_st[df_st['patientunitstayid'] == i]['T'].values[0]\n",
    "    censor_days.append(censor_day)\n",
    "\n",
    "df_censor['censor'] = censor_days\n",
    "df_censor = df_censor.reset_index(drop=True)\n",
    "df_censor = df_censor[['patientunitstayid', 'censor']].reset_index(drop=True)\n",
    "\n",
    "df_st = pd.merge(df_st, df_censor, on='patientunitstayid')\n",
    "\n",
    "# Getting Mortality Information\n",
    "df_pat = df_patient_mim[['patientunitstayid', 'hospitaldischargeoffset', 'hospitaldischargelocation']]\n",
    "df_pat = df_pat.dropna(subset=['patientunitstayid', 'hospitaldischargelocation', 'hospitaldischargeoffset'])\n",
    "df_pat['hospitaldischargestatus'] = df_pat['hospitaldischargelocation'].apply(get_status)\n",
    "df_pat['duration_day'] = df_pat['hospitaldischargeoffset']\n",
    "\n",
    "# # Do we treat people who died after 28 days as alive? And set duration to 28 days?\n",
    "df_pat.loc[df_pat['duration_day'] >= 28, 'hospitaldischargestatus'] = 0\n",
    "df_pat.loc[df_pat['duration_day'] >= 28, 'duration_day'] = 28\n",
    "df_pat = df_pat[df_pat['duration_day'] >= 0]\n",
    "\n",
    "if remove_event_before_grace:\n",
    "    str_day = grace_days_consider[-1]\n",
    "    day = get_day(str_day)\n",
    "    df_pat = df_pat[df_pat['duration_day'] >= day]\n",
    "\n",
    "df_st_pat = pd.merge(df_st, df_pat, on='patientunitstayid')\n",
    "df_st_pat['treatment_day'] = df_st_pat['treatment_day'].apply(get_day)\n",
    "df_st_pat['censor'] = df_st_pat['censor'].apply(get_day)\n",
    "\n",
    "if create_clones_before_grace_outcome:\n",
    "    temp = df_st_pat[df_st_pat['duration_day'] < get_day(grace_days_consider[-1])]\n",
    "    # Make treated clones\n",
    "    df_untreated_to_treated = temp[temp['T'] == 0]\n",
    "    df_untreated_to_treated['T'] = 1\n",
    "    df_untreated_to_treated['treatment_day'] = 1\n",
    "    # df_untreated_to_treated['hospitaldischargestatus'] = 0 # censor these patients?\n",
    "    # Make untreated clones\n",
    "    df_treated_to_untreated = temp[temp['T'] == 1]\n",
    "    df_treated_to_untreated['T'] = 0\n",
    "    df_treated_to_untreated['treatment_day'] = 0\n",
    "    # df_treated_to_untreated['hospitaldischargestatus'] = 0 # censor these patients?\n",
    "    df_st_pat = pd.concat([df_st_pat, df_untreated_to_treated, df_treated_to_untreated]).reset_index(drop=True)\n",
    "\n",
    "if remove_immortal_time_treated:\n",
    "    df_st_pat = pd.merge(df_st_pat, df_st_follow_time, on='patientunitstayid')\n",
    "    df_st_pat.loc[df_st_pat['T'] == 0, 'follow-up-time'] = 0\n",
    "    df_st_pat['follow-up-time'] = df_st_pat['follow-up-time'] / 1440\n",
    "    df_st_pat['duration_day'] = df_st_pat['duration_day'] - df_st_pat['follow-up-time']\n",
    "    df_st_pat = df_st_pat[df_st_pat['duration_day'] > 0]\n",
    "\n",
    "# Figure out real duration with Day 0 based on treatment (steroid > 160)\n",
    "df_st_pat['temp_treatment_day'] = 0\n",
    "df_st_pat.loc[df_st_pat['treatment_day'] >= 1, 'temp_treatment_day'] = df_st_pat['treatment_day'] - 1\n",
    "df_st_pat['duration_real'] = df_st_pat['duration_day'] - df_st_pat['temp_treatment_day'] \n",
    "# Figure out duration if censoring for each patient\n",
    "df_st_pat['duration_censor'] = df_st_pat['censor'] - df_st_pat['treatment_day']\n",
    "# Some patients die on the day they are treated - treat their duration as 0\n",
    "df_st_pat[(df_st_pat['duration_real'] < 0) & (df_st_pat['duration_real'] > -1)] = 0\n",
    "# Small number of patients have duration much smaller than treatment - weird samples\n",
    "df_st_pat = df_st_pat[df_st_pat['duration_real'] > 0]\n",
    "\n",
    "if perform_censoring:\n",
    "    # Account for censoring in duration\n",
    "    df_st_pat['duration_final'] = df_st_pat[['duration_censor','duration_real']].min(axis=1)\n",
    "elif remove_censored:\n",
    "    # Remove patients who were censored due to retreatment\n",
    "    df_st_pat['duration_censor'] = df_st_pat['duration_censor'].replace(np.inf, 1000)\n",
    "    df_st_pat = df_st_pat[df_st_pat.duration_real <= df_st_pat.duration_censor]\n",
    "    df_st_pat['duration_final'] = df_st_pat['duration_real']\n",
    "else:\n",
    "    # Do not Account for censoring in duration\n",
    "    df_st_pat['duration_final'] = df_st_pat['duration_real']\n",
    "\n",
    "df_temp = df_st_pat.copy(deep=True)\n",
    "df_st_pat = df_st_pat[['patientunitstayid', 'T', 'hospitaldischargestatus', 'hospitaldischargelocation', 'duration_final', 'duration_real', 'duration_day', 'duration_censor', 'treatment_day']]\n",
    "df_st_pat = df_st_pat.reset_index(drop=True)\n",
    "\n",
    "# Other Categories are censored (set to 0 at duration)\n",
    "# Discarge events are extended to best case\n",
    "if extend_discharge_best_case:\n",
    "    df_st_pat['hospitaldischargelocation_coded'] =  df_st_pat[\"hospitaldischargelocation\"].map({'HOME HEALTH CARE':1,\n",
    "                                            'CHRONIC/LONG TERM ACUTE CARE':1, 'SKILLED NURSING FACILITY':1,\n",
    "                                               'HOME':1, 'REHAB':1, 'DIED':0, 'ACUTE HOSPITAL':0,\n",
    "                                                        'HOSPICE':0, 'PSYCH FACILITY':1, 'OTHER FACILITY':1,\n",
    "                                                            'AGAINST ADVICE':1, 'HEALTHCARE FACILITY':1,\n",
    "                                                                'ASSISTED LIVING':1})\n",
    "\n",
    "    # Best-Outcome Censoring for those that have discarge\n",
    "    df_st_pat.loc[df_st_pat[\"hospitaldischargelocation_coded\"] == 1, \"duration_final\"] = 28\n",
    "    \n",
    "if sub_component_analysis:\n",
    "    df_st_pat = pd.merge(df_st_pat, df_sofa_comps_mim, on='patientunitstayid')\n",
    "    if cv:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Cardiovascular_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Cardiovascular_score'] < 2]\n",
    "    elif resp:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Respiration_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Respiration_score'] < 2]\n",
    "    elif cns:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['CNS_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['CNS_score'] < 2]\n",
    "    elif liv:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Liver_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Liver_score'] < 2]\n",
    "    elif coag:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Coagulation_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Coagulation_score'] < 2]\n",
    "    elif rn:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Renal_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Renal_score'] < 2]\n",
    "    df_st_pat = df_st_pat.drop(columns=['Cardiovascular_score', 'Respiration_score', 'CNS_score', 'Liver_score', 'Coagulation_score', 'Renal_score'])\n",
    "    \n",
    "try:\n",
    "    zx_group = int(sepsis_zx_subtype)\n",
    "    subtype_patients = df_zx_subtypes_mim[df_zx_subtypes_mim['subtype'] == zx_group]['patientunitstayid'].values\n",
    "    df_st_pat = df_st_pat[df_st_pat['patientunitstayid'].isin(subtype_patients)]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_st_pat_mim = df_st_pat.copy(deep=True)\n",
    "\n",
    "df_feat = df_features_mim.copy(deep=True)\n",
    "df_feat = df_feat[df_feat['patientunitstayid'].isin(df_st_pat['patientunitstayid'].values)]\n",
    "feat_day_titles = [\"day_\" + str(i+1) for i in range(28)]\n",
    "\n",
    "df_feat_mimic_for_demo = df_feat.copy(deep=True)\n",
    "\n",
    "# Drop Extremely Missing Features\n",
    "## Bicarbonate, CRP\n",
    "time_feature_names = ['Albumin', 'ALT', 'AST', 'Bands', 'Bilirubin',\n",
    "                 'BUN','Chloride', 'Creatinine', 'FiO2', 'Glucose', 'Heart_rate',\n",
    "                 'Hemoglobin', 'INR', 'MAP', 'Lymphocyte_count', 'Lactate', 'GCS',\n",
    "                 'PaO2', 'Platelet', 'Respiratory_rate','SO2', 'Sodium','Systolic_ABP',\n",
    "                 'Temperature', 'Troponin T', 'Urine', 'WBC']\n",
    "baseline_feature_names = ['age', 'gender', 'BMI', 'sofa', 'Respiration_score', 'comorbidity_score'\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score']\n",
    "\n",
    "# Missingness for Baseline Confounders\n",
    "imp_mean = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "df_feat.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "df_feat['gender'] = df_feat['gender'].fillna(\"Missing\")\n",
    "one_hot_gender = pd.get_dummies(df_feat['gender'])\n",
    "df_feat = df_feat.drop('gender',axis = 1)\n",
    "df_feat = df_feat.join(one_hot_gender)\n",
    "df_feat = df_feat.rename(columns={\"Female\": \"gender_Female\", \"Male\": \"gender_Male\",\n",
    "                                 \"Unknown\": \"gender_Unknown\"})\n",
    "if 'gender_Unknown' in df_feat:\n",
    "    df_feat['gender_Missing'] = df_feat['gender_Unknown']\n",
    "    df_feat.drop(columns=['gender_Unknown'], inplace=True)\n",
    "else:\n",
    "    df_feat['gender_Missing'] = 0\n",
    "\n",
    "num_vars = ['Albumin', 'ALT', 'AST', 'Bands',\n",
    "                     'Bilirubin', 'BUN', 'Chloride', 'Creatinine',\n",
    "                     'FiO2', 'Glucose', 'Heart_rate', 'Hemoglobin',\n",
    "                     'INR', 'MAP', 'PaO2', 'Lymphocyte_count', 'Lactate', 'GCS',\n",
    "                     'Platelet', 'Respiratory_rate', 'SO2', 'Sodium',\n",
    "                     'Systolic_ABP', 'Temperature', 'Troponin T',\n",
    "                     'Urine', 'WBC']\n",
    "num_feats = ['age', 'BMI']\n",
    "for i in range(0, 28):\n",
    "    for var in num_vars:\n",
    "        num_feats.append(f\"{var}_day_{i+1}\")\n",
    "df_feat[num_feats] = clean_outliers(df_feat[num_feats])\n",
    "df_feat['age_missing'] = df_feat['age'].isnull().astype(int)\n",
    "df_feat['BMI_missing'] = df_feat['BMI'].isnull().astype(int)\n",
    "df_feat['age'] = imp_mean.fit_transform(df_feat['age'].values.reshape(-1,1))[:,0]\n",
    "df_feat['BMI'] = imp_mean.fit_transform(df_feat['BMI'].values.reshape(-1,1))[:,0]\n",
    "df_feat['sofa'] = imp_mean.fit_transform(df_feat['sofa'].values.reshape(-1,1))[:,0]\n",
    "\n",
    "# Quantizing BMI\n",
    "df_feat['BMI_quant'] = df_feat['BMI'].apply(quantize_bmi)\n",
    "df_feat['BMI_orig'] = df_feat['BMI']\n",
    "df_feat['BMI'] = df_feat['BMI_quant']\n",
    "\n",
    "# Quantizing Age\n",
    "df_feat['age_quant'] = pd.cut(df_feat['age'], bins=age_bins, labels=[0,1,2,3,4], include_lowest=True)\n",
    "df_feat['age_orig'] = df_feat['age']\n",
    "df_feat['age'] = df_feat['age_quant']\n",
    "imp_median = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "df_feat['age'] = df_feat['age'].astype(float)\n",
    "df_feat['age'] = imp_median.fit_transform(df_feat['age'].values.reshape(-1,1))\n",
    "df_feat['age'] = df_feat['age'].astype(int)\n",
    "\n",
    "# Missingness for Time Varying Covariates\n",
    "for tv_feature in time_feature_names:\n",
    "    tv_feature_all = [tv_feature + '_' + day_title for day_title in feat_day_titles]\n",
    "    df_feat[tv_feature_all] = clean_outliers(df_feat[tv_feature_all])\n",
    "    df_feat[tv_feature_all] = df_feat[tv_feature_all].ffill(axis = 1)\n",
    "    df_feat[tv_feature_all] = imp_mean.fit_transform(df_feat[tv_feature_all])\n",
    "    \n",
    "# Point Treatments (Get Day of Treatment for Treated) \n",
    "df_confounder_list = []\n",
    "base_features = ['age', 'gender_Male', 'gender_Missing', 'BMI', 'age_missing',\n",
    "                 'BMI_missing', 'sofa', 'Respiration_score', 'comorbidity_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score']\n",
    "col_titles = ['patientunitstayid'] + time_feature_names + base_features\n",
    "\n",
    "\n",
    "for pat, T in zip(df_st_pat['patientunitstayid'].values, df_st_pat['T'].values):\n",
    "    treatment_day = df_st_pat[(df_st_pat['patientunitstayid'] == pat) & (df_st_pat['T'] == T)]['treatment_day'].values[0]\n",
    "    if treatment_day == 0:\n",
    "        treatment_day = 1\n",
    "    tv_point_features = [feat + '_day_' + str(treatment_day) for feat in time_feature_names]\n",
    "    confounders =  tv_point_features + base_features\n",
    "    df_feat_temp = df_feat[df_feat['patientunitstayid'] == pat]\n",
    "    df_feat_temp = df_feat_temp[['patientunitstayid'] + confounders].reset_index(drop=True)\n",
    "    df_feat_temp.columns = col_titles\n",
    "    df_feat_temp['T'] = T\n",
    "    df_confounder_list.append(df_feat_temp)\n",
    "    \n",
    "df_confounders_mim = pd.concat(df_confounder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c96ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eicu = pd.merge(df_confounders_eicu, df_st_pat_eicu, on=['patientunitstayid', 'T'])\n",
    "df_mim = pd.merge(df_confounders_mim, df_st_pat_mim, on=['patientunitstayid', 'T'])\n",
    "overlapping_columns = (list(set(list(df_mim)) & set(list(df_eicu))))\n",
    "overlapping_columns.insert(0, overlapping_columns.pop(overlapping_columns.index('patientunitstayid')))\n",
    "df_mim = df_mim[overlapping_columns]\n",
    "df_mim['dataset'] = 0\n",
    "df_eicu = df_eicu[overlapping_columns]\n",
    "df_eicu['dataset'] = 1\n",
    "df = pd.concat([df_mim, df_eicu])\n",
    "X = df.copy(deep=True)\n",
    "\n",
    "X_treated = X[X['T'] == 1]\n",
    "X_untreated = X[X['T'] == 0]\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(f\"Naive 28 Day Cumulative Incidence for Treated: {np.round(X_treated[X_treated['hospitaldischargestatus'] == 1].shape[0]/len(X_treated), 3)}\")\n",
    "print(f\"Naive 28 Day Cumulative Incidence for Untreated: {np.round(X_untreated[X_untreated['hospitaldischargestatus'] == 1].shape[0]/len(X_untreated), 3)}\")\n",
    "print(f\"Percent of Patients Who Died: {X[X['hospitaldischargestatus'] == 1].shape[0] / X.shape[0]}\")\n",
    "\n",
    "print(f\"Alive Length for Treated: {np.round(X_treated['duration_final'].mean(), 2)}±{np.round(X_treated['duration_final'].std(), 2)}\")\n",
    "print(f\"Alive Length for Untreated: {np.round(X_untreated['duration_final'].mean(), 2)}±{np.round(X_untreated['duration_final'].std(), 2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "112c50f0",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da6fad28",
   "metadata": {},
   "source": [
    "### Balancing Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b554a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eicu = pd.merge(df_confounders_eicu, df_st_pat_eicu, on=['patientunitstayid', 'T'])\n",
    "df_mim = pd.merge(df_confounders_mim, df_st_pat_mim, on=['patientunitstayid', 'T'])\n",
    "overlapping_columns = (list(set(list(df_mim)) & set(list(df_eicu))))\n",
    "overlapping_columns.insert(0, overlapping_columns.pop(overlapping_columns.index('patientunitstayid')))\n",
    "df_mim = df_mim[overlapping_columns]\n",
    "df_mim['dataset'] = 0\n",
    "df_eicu = df_eicu[overlapping_columns]\n",
    "df_eicu['dataset'] = 1\n",
    "df = pd.concat([df_mim, df_eicu])\n",
    "\n",
    "overlapping_columns.append('dataset')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "keep_certain_level_sofa = 0\n",
    "if keep_certain_level_sofa:\n",
    "    lower_level = 8\n",
    "    higher_level = 25\n",
    "    df = df[(df['sofa'] >= lower_level) & (df['sofa'] <= higher_level)].reset_index(drop=True)\n",
    "\n",
    "patient_id = ['patientunitstayid']\n",
    "misc_vars = ['T', 'hospitaldischargestatus', 'duration_final', 'duration_real', 'hospitaldischargelocation']\n",
    "cat_vars = ['gender_Male', 'dataset']\n",
    "num_vars = ['Albumin', 'ALT', 'AST', 'Bands', 'Bicarbonate',\n",
    "                     'Bilirubin', 'BUN', 'Chloride', 'Creatinine', 'CRP',\n",
    "                     'FiO2', 'GCS', 'Glucose', 'Heart_rate', 'Hemoglobin',\n",
    "                     'INR', 'Lactate', 'Lymphocyte_percent', 'MAP', 'PaO2',\n",
    "                     'Platelet', 'RDW', 'Respiratory_rate', 'SO2', 'Sodium',\n",
    "                     'Systolic_ABP', 'Temperature', 'Troponin I', 'Troponin T',\n",
    "                     'Urine', 'WBC', 'comorbidity_score', 'sofa', 'Respiration_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score', 'age', 'BMI']\n",
    "discrete_vars = ['gender_Male', 'dataset']\n",
    "continuous_vars = ['Albumin', 'ALT', 'AST', 'Bands', 'Bicarbonate',\n",
    "                     'Bilirubin', 'BUN', 'Chloride', 'Creatinine', 'CRP',\n",
    "                     'FiO2', 'GCS', 'Glucose', 'Heart_rate', 'Hemoglobin',\n",
    "                     'INR', 'Lactate', 'Lymphocyte_percent', 'MAP', 'PaO2',\n",
    "                     'Platelet', 'RDW', 'Respiratory_rate', 'SO2', 'Sodium',\n",
    "                     'Systolic_ABP', 'Temperature', 'Troponin I', 'Troponin T',\n",
    "                     'Urine', 'WBC', 'comorbidity_score', 'age', 'Respiration_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score', 'BMI']\n",
    "\n",
    "cat_vars = (list(set(list(cat_vars)) & set(list(overlapping_columns))))\n",
    "num_vars = (list(set(list(num_vars)) & set(list(overlapping_columns))))\n",
    "discrete_vars = (list(set(list(discrete_vars)) & set(list(overlapping_columns))))\n",
    "continuous_vars = (list(set(list(continuous_vars)) & set(list(overlapping_columns))))\n",
    "\n",
    "all_vars = num_vars + cat_vars\n",
    "\n",
    "# Remove colzumns with no differences in values across patients\n",
    "for col in all_vars:\n",
    "    if col == 'dataset':\n",
    "        continue\n",
    "    if (df[col] == df[col][0]).all():\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "        all_vars.remove(col)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[num_vars] = scaler.fit_transform(df[num_vars])\n",
    "X = df.drop(columns=['patientunitstayid', 'treatment_day'])\n",
    "\n",
    "# Removing sofa from analysis bc we have components\n",
    "use_vars = copy.deepcopy(all_vars)\n",
    "use_vars.remove('sofa')\n",
    "\n",
    "if remove_missing_feats:\n",
    "    use_vars.remove('ALT')\n",
    "    use_vars.remove('AST')\n",
    "    use_vars.remove('Albumin')\n",
    "    use_vars.remove('Bands')\n",
    "    use_vars.remove('Troponin T')\n",
    "\n",
    "imp_covariates = []\n",
    "X_matched = perform_balancing_method3(X, imp_covariates, use_vars, use_caliper=True)\n",
    "X = X_matched.copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "X_save = X.copy(deep=True)\n",
    "X_save[num_vars] = scaler.inverse_transform(X_save[num_vars])\n",
    "\n",
    "if save_data:\n",
    "    add_on = ''\n",
    "    if keep_certain_level_sofa == 0 and sepsis_zx_subtype == 'NONE':\n",
    "        add_on = ''\n",
    "    elif keep_certain_level_sofa == 0 and sepsis_zx_subtype == '1':\n",
    "        add_on = '_ri'\n",
    "    elif keep_certain_level_sofa == 0 and sepsis_zx_subtype == '3':\n",
    "        add_on = '_rw'\n",
    "    elif keep_certain_level_sofa == 1 and lower_level == 0 and higher_level == 7:\n",
    "        add_on = '_sofa_low'\n",
    "    elif keep_certain_level_sofa == 1 and lower_level == 8:\n",
    "        add_on = '_sofa_high'\n",
    "    X_save.to_csv(f\"Results/combined_data_matched{add_on}.csv\", index=False)\n",
    "\n",
    "print(f\"Number of Treated Patients: {X[X['T'] == 1].shape[0]}\")\n",
    "print(f\"Percent of Patients Who Died: {X[X['hospitaldischargestatus'] == 1].shape[0] / X.shape[0]}\")\n",
    "\n",
    "balances = check_balance_after_matching(X, use_vars)\n",
    "print('Number of unbalanced covariates: ' + str((balances>smd_threshold).sum()))\n",
    "balances[balances > smd_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of propensity scores and weights\n",
    "treatment = X[X['T'] == 1]\n",
    "control = X[X['T'] == 0]\n",
    "\n",
    "plt.figure(figsize=(15, 6)) # Increase the width to better accommodate three subplots\n",
    "\n",
    "plt.subplot(1, 3, 1) # Change subplot layout to 1 row, 3 columns\n",
    "plt.hist(treatment['ps'], alpha=0.5, label='Treatment', density=True)\n",
    "plt.hist(control['ps'], alpha=0.5, label='Control', density=True)\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3) # Change subplot layout to 1 row, 3 columns\n",
    "other_var = 'Lactate'\n",
    "plt.hist(treatment[other_var], alpha=0.5, label='Treatment', density=True)\n",
    "plt.hist(control[other_var], alpha=0.5, label='Control', density=True)\n",
    "plt.xlabel(other_var)\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97093e39",
   "metadata": {},
   "source": [
    "#### Cumulative Incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee0b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['outcome'] =  X[\"hospitaldischargelocation\"].map({'HOME HEALTH CARE':2,\n",
    "                                            'CHRONIC/LONG TERM ACUTE CARE':2, 'SKILLED NURSING FACILITY':2,\n",
    "                                               'HOME':2, 'REHAB':2, 'DIED':1, 'ACUTE HOSPITAL':2,\n",
    "                                                        'HOSPICE':2, 'PSYCH FACILITY':2, 'OTHER FACILITY':0,\n",
    "                                                            'AGAINST ADVICE':0, 'HEALTHCARE FACILITY':2,\n",
    "                                                                'ASSISTED LIVING':2, 'Other External':0,\n",
    "                                                        'Other Hospital':0, 'Skilled Nursing Facility':2,\n",
    "                                                           'Home':2, 'Rehabilitation':2, 'Death':1,\n",
    "                                                                    'Nursing Home':2, 'Other':0})\n",
    "\n",
    "X_treated = X[X['T'] == 1]\n",
    "X_untreated = X[X['T'] == 0]\n",
    "\n",
    "print(f\"Naive 28 Day Cumulative Incidence for Treated: {np.round(X_treated[X_treated['hospitaldischargestatus'] == 1].shape[0]/len(X_treated), 3)}\")\n",
    "print(f\"Naive 28 Day Cumulative Incidence for Untreated: {np.round(X_untreated[X_untreated['hospitaldischargestatus'] == 1].shape[0]/len(X_untreated), 3)}\")\n",
    "print(f\"Percent of Patients Who Died: {X[X['hospitaldischargestatus'] == 1].shape[0] / X.shape[0]}\")\n",
    "\n",
    "print(f\"Alive Length for Treated: {np.round(X_treated['duration_final'].mean(), 2)}±{np.round(X_treated['duration_final'].std(), 2)}\")\n",
    "print(f\"Alive Length for Untreated: {np.round(X_untreated['duration_final'].mean(), 2)}±{np.round(X_untreated['duration_final'].std(), 2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e67ed6",
   "metadata": {},
   "source": [
    "#### Cox Proportional Hazard Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df23cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cph = CoxPHFitter(penalizer=0.1)\n",
    "features = use_vars + ['T', 'duration_final', 'hospitaldischargestatus']\n",
    "\n",
    "data_cox = X[features]\n",
    "for col in list(data_cox):\n",
    "    if (data_cox[col] == data_cox[col][0]).all():\n",
    "        data_cox.drop(columns=[col], inplace=True)\n",
    "\n",
    "cph.fit(data_cox, duration_col='duration_final', event_col='hospitaldischargestatus',\n",
    "robust=True)\n",
    "cph.print_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db6dcdd2",
   "metadata": {},
   "source": [
    "#### Kaplan Meier Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "T = data_cox['duration_final']\n",
    "E = data_cox['hospitaldischargestatus']\n",
    "\n",
    "# fit the model for overall survival\n",
    "kmf.fit(T, event_observed=E)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "# fit the model for each treatment T and plot\n",
    "for name, grouped_df in data_cox.groupby('T'):\n",
    "    if name == 0:\n",
    "        label = 'Untreated'\n",
    "    else:\n",
    "        label = 'Treated'\n",
    "    kmf.fit(grouped_df['duration_final'], grouped_df['hospitaldischargestatus'], label=label)\n",
    "    kmf.plot()\n",
    "\n",
    "# plt.title('K-M Plots')\n",
    "plt.xlabel('Days', fontsize=14)  # set x-axis label\n",
    "plt.ylabel('Survival Function', fontsize=14)  # set y-axis label\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.ylim(0.6, 1.02)  # set y-axis limits\n",
    "plt.yticks(np.arange(0.6, 1.02, 0.05))  # set y-axis ticks\n",
    "\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
