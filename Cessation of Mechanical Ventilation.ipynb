{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77292963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from coxph_fitter import CoxPHFitter\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lifelines\n",
    "import copy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.impute import IterativeImputer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rs = 42\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e90eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_threshold = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4af23723",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a22588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(data):\n",
    "    cols = list(data)\n",
    "    for col in cols:\n",
    "        min_value = data[col].quantile(0.01)\n",
    "        max_value = data[col].quantile(0.99)\n",
    "        data[col][data[col] < min_value] = None\n",
    "        data[col][data[col] > max_value] = None\n",
    "    return data\n",
    "\n",
    "def quantize_bmi(cell):\n",
    "    if cell < 18.5:\n",
    "        return 0\n",
    "    elif cell <= 24.9:\n",
    "        return 1\n",
    "    elif cell <= 29.9:\n",
    "        return 2\n",
    "    elif cell <= 34.9:\n",
    "        return 3\n",
    "    elif cell <= 39:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "def get_status(cell):\n",
    "    if cell == 'DIED':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def cal_weights(event, logits_treatment, stabilized=True, clip = True):\n",
    "    ones_idx, zeros_idx = np.where(event == 1), np.where(event == 0)\n",
    "    p_T = len(ones_idx[0]) / (len(ones_idx[0]) + len(zeros_idx[0]))\n",
    "    if stabilized:\n",
    "        # stabilized weights:   treated_w.sum() + controlled_w.sum() ~ N\n",
    "        treated_w, controlled_w = p_T / logits_treatment[ones_idx], (1 - p_T) / (1. - logits_treatment[zeros_idx])\n",
    "    else:\n",
    "        # standard IPTW:  treated_w.sum() + controlled_w.sum() > N\n",
    "        treated_w, controlled_w = 1. / logits_treatment[ones_idx], 1. / (1. - logits_treatment[zeros_idx])\n",
    "\n",
    "    if clip:\n",
    "        # treated_w = np.clip(treated_w, a_min=1e-06, a_max=100)\n",
    "        # controlled_w = np.clip(controlled_w, a_min=1e-06, a_max=100)\n",
    "        amin = np.quantile(np.concatenate((treated_w, controlled_w)), 0.01)\n",
    "        amax = np.quantile(np.concatenate((treated_w, controlled_w)), 0.99)\n",
    "        print('Using IPTW trim [{}, {}]'.format(amin, amax))\n",
    "        treated_w = np.clip(treated_w, a_min=amin, a_max=amax)\n",
    "        controlled_w = np.clip(controlled_w, a_min=amin, a_max=amax)\n",
    "\n",
    "    treated_w, controlled_w = np.reshape(treated_w, (len(treated_w), 1)), np.reshape(controlled_w,\n",
    "                                                                                     (len(controlled_w), 1))\n",
    "    return treated_w, controlled_w\n",
    "\n",
    "\n",
    "def get_day(cell):\n",
    "    if cell == np.inf:\n",
    "        return cell\n",
    "    return int(cell[4:])\n",
    "\n",
    "def get_window_lists(cell):\n",
    "    day = get_day(cell)\n",
    "    l = []\n",
    "    for i in range(0, day+1):\n",
    "        l.append('day_' + str(i))\n",
    "    return l  \n",
    "\n",
    "def get_window_lists_adj(cell, no_censor_window=None):\n",
    "    day = get_day(cell)\n",
    "    l = []\n",
    "    for i in range(0, day+1+no_censor_window):\n",
    "        if i < 29: # only 28 days available\n",
    "            l.append('day_' + str(i))\n",
    "    return l  \n",
    "\n",
    "def check_balance_before_IPTW(X, all_vars):\n",
    "    feature_treatment = X[X['T'] == 1][all_vars]\n",
    "    feature_control = X[X['T'] == 0][all_vars]\n",
    "\n",
    "    treatment_mean = feature_treatment.mean(0)\n",
    "    treatment_std = feature_treatment.std(0)\n",
    "\n",
    "    control_mean = feature_control.mean(0)\n",
    "    control_std = feature_control.std(0)\n",
    "\n",
    "    SMD = np.abs(treatment_mean-control_mean) / np.sqrt((treatment_std**2 + control_std**2)/2)\n",
    "\n",
    "    print('Number of unbalanced covariates: ' + str((SMD>smd_threshold).sum()))\n",
    "\n",
    "    return SMD\n",
    "\n",
    "\n",
    "def check_balance_after_matching(X, all_vars):\n",
    "    feature_treatment = X[X['T'] == 1][all_vars]\n",
    "    feature_control = X[X['T'] == 0][all_vars]\n",
    "\n",
    "    treatment_mean = feature_treatment.mean(0)\n",
    "    treatment_std = feature_treatment.std(0)\n",
    "\n",
    "    control_mean = feature_control.mean(0)\n",
    "    control_std = feature_control.std(0)\n",
    "\n",
    "    SMD = np.abs(treatment_mean-control_mean) / np.sqrt((treatment_std**2 + control_std**2)/2)\n",
    "\n",
    "    return SMD\n",
    "\n",
    "def check_balance_after_IPTW(X, all_vars):\n",
    "    feature_treatment = X[X['T'] == 1][all_vars]\n",
    "    feature_control = X[X['T'] == 0][all_vars]\n",
    "\n",
    "    cohort_treatment = X[X['T'] == 1]['weight']\n",
    "    cohort_control = X[X['T'] == 0]['weight']\n",
    "\n",
    "    weight = np.array(cohort_treatment.values)\n",
    "    weight_sum = (weight).sum()\n",
    "    weight_2_sum = (weight ** 2).sum()\n",
    "\n",
    "    treatment_mean = (feature_treatment * weight[:,np.newaxis]).sum(0) / weight_sum\n",
    "    treatment_std = np.sqrt((weight_sum) / (weight_sum ** 2 - weight_2_sum) * (weight[:, np.newaxis] * ((feature_treatment - treatment_mean[np.newaxis,:]) ** 2)).sum(0))\n",
    "\n",
    "    weight = np.array(cohort_control.values)\n",
    "    weight_sum = (weight).sum()\n",
    "    weight_2_sum = (weight ** 2).sum()\n",
    "\n",
    "    control_mean = (feature_control * weight[:, np.newaxis]).sum(0) / weight_sum\n",
    "    control_std = np.sqrt((weight_sum) / (weight_sum ** 2 - weight_2_sum) * (weight[:, np.newaxis] * ((feature_control - control_mean[np.newaxis, :]) ** 2)).sum(0))\n",
    "\n",
    "    SMD = np.abs(treatment_mean-control_mean) / np.sqrt((treatment_std**2 + control_std**2)/2)\n",
    "\n",
    "    print('Number of unbalanced covariates: ' + str((SMD>smd_threshold).sum()))\n",
    "    return SMD\n",
    "\n",
    "\n",
    "def run_ps(df, X, T, Y):\n",
    "    # estimate the propensity score\n",
    "    temp = df.copy(deep=True)\n",
    "    ps = LogisticRegression().fit(temp[X], temp[T]).predict_proba(temp[X])[:, 1]\n",
    "    treated_w, controlled_w = cal_weights(temp[T].values, ps, stabilized=False)\n",
    "    ones_idx, zeros_idx = np.where(temp[T].values == 1), np.where(temp[T].values == 0)\n",
    "    weight = np.zeros(len(temp[T].values))\n",
    "    weight[ones_idx] = treated_w.squeeze()\n",
    "    weight[zeros_idx] = controlled_w.squeeze()\n",
    "    temp['weight'] = weight\n",
    "    treatment_effect = sum(temp.query(\"T==1\")[Y]*temp.query(\"T==1\")[\"weight\"]) / len(temp)\n",
    "    no_treatment_effect = sum(temp.query(\"T==0\")[Y]*temp.query(\"T==0\")[\"weight\"]) / len(temp)\n",
    "    return [treatment_effect, no_treatment_effect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching Iteratively\n",
    "\n",
    "# Utility to define caliper for Mahalanobis distance\n",
    "# median absolute deviation (MAD) of the calculated distances\n",
    "def mad(arr):\n",
    "    med = np.median(arr)\n",
    "    return np.median(np.abs(arr - med))\n",
    "\n",
    "def calculate_propensity_scores(X, treatment_col, covariate_list):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X[covariate_list], X[treatment_col])\n",
    "    propensity_scores = model.predict_proba(X[covariate_list])[:, 1]\n",
    "    X['ps'] = propensity_scores\n",
    "    return X\n",
    "\n",
    "def match_pairs(distances, treated_idx, control_idx, N=1, caliper=None):\n",
    "    matched_pairs = []\n",
    "    control_pool = copy.deepcopy(control_idx)\n",
    "    distance_pool = copy.deepcopy(distances)\n",
    "    matches_per_treated = dict.fromkeys(treated_idx, 0)\n",
    "    unmatchable = set()\n",
    "    while len(control_pool) > 0:\n",
    "        for i, treated in enumerate(treated_idx):\n",
    "            if treated in unmatchable or matches_per_treated[treated] >= N:\n",
    "                continue\n",
    "            if control_pool.empty:\n",
    "                break\n",
    "            min_index = np.argmin(distance_pool[i])\n",
    "            min_distance = distance_pool[i, min_index]\n",
    "            if caliper is not None and min_distance > caliper:\n",
    "                unmatchable.add(treated)\n",
    "                continue\n",
    "            matched_control = control_pool[min_index]\n",
    "            matched_pairs.append((treated, matched_control))\n",
    "            matches_per_treated[treated] += 1\n",
    "            control_pool = control_pool.drop(matched_control)\n",
    "            distance_pool = np.delete(distance_pool, min_index, axis=1)\n",
    "        if min(val for key, val in matches_per_treated.items() if key not in unmatchable) >= N:\n",
    "            break\n",
    "    return matched_pairs\n",
    "\n",
    "def iterative_matching(X, unbalanced_covariates, treatment_col, method='propensity', allow_repetition=False, use_caliper=False):\n",
    "    treated_idx = X[X[treatment_col] == 1].index\n",
    "    control_idx = X[X[treatment_col] == 0].index\n",
    "    running_data = X.copy(deep=True)\n",
    "    matched_pairs = []\n",
    "    for i, covariate in enumerate(unbalanced_covariates):\n",
    "        multiplier = 1\n",
    "        if i == 0:\n",
    "            distances = calculate_distance(running_data, treated_idx, control_idx, covariate, treatment_col, method)\n",
    "            if (covariate in continuous_vars) and use_caliper:\n",
    "                flat_distances = distances.flatten()\n",
    "                caliper = multiplier * mad(flat_distances)\n",
    "            else:\n",
    "                caliper = None\n",
    "            pairs = match_pairs(distances, treated_idx, control_idx, allow_repetition=allow_repetition, caliper=caliper)\n",
    "            matched_pairs = pairs\n",
    "        else:\n",
    "            matched_indices = [idx for pair in matched_pairs for idx in pair]\n",
    "            running_data = running_data.loc[matched_indices]\n",
    "            treated_idx = running_data[running_data[treatment_col] == 1].index\n",
    "            control_idx = running_data[running_data[treatment_col] == 0].index\n",
    "            distances = calculate_distance(running_data, treated_idx, control_idx, covariate, treatment_col, method)\n",
    "            if (covariate in continuous_vars) and use_caliper:\n",
    "                flat_distances = distances.flatten()\n",
    "                caliper = multiplier * mad(flat_distances)\n",
    "            else:\n",
    "                caliper = None\n",
    "            pairs = match_pairs(distances, treated_idx, control_idx, allow_repetition=allow_repetition, caliper=caliper)\n",
    "            matched_pairs = pairs\n",
    "    return matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_propensity(X, treated_idx, control_idx, covariates, treatment_col):\n",
    "    X_ps = calculate_propensity_scores(X, treatment_col, covariates)\n",
    "    treated_data = X_ps.loc[treated_idx, 'ps'].values.reshape(-1, 1)\n",
    "    control_data = X_ps.loc[control_idx, 'ps'].values.reshape(-1, 1)\n",
    "    distances = distance.cdist(treated_data, control_data, metric='mahalanobis')\n",
    "    return distances, X_ps\n",
    "\n",
    "\n",
    "def matching_propensity(X, unbalanced_covariates, treatment_col, N=1, allow_repetition=False, use_caliper=False):\n",
    "    treated_idx = X[X[treatment_col] == 1].index\n",
    "    control_idx = X[X[treatment_col] == 0].index\n",
    "    running_data = X.copy(deep=True)\n",
    "    matched_pairs = []\n",
    "    multiplier = 1\n",
    "    distances, X_ps = calculate_distance_propensity(running_data, treated_idx, control_idx, unbalanced_covariates, treatment_col)\n",
    "    flat_distances = distances.flatten()\n",
    "    caliper = multiplier * mad(flat_distances)\n",
    "    pairs = match_pairs(distances, treated_idx, control_idx, N=N, caliper=caliper)\n",
    "    matched_pairs = pairs\n",
    "    return matched_pairs, X_ps\n",
    "\n",
    "\n",
    "def perform_balancing_method2(X, imp_covariates, all_vars, use_caliper=True):\n",
    "    treatment_col = 'T'\n",
    "    # Matching Based on Important Covariates\n",
    "    if len(imp_covariates) > 0:\n",
    "        matched_pairs = iterative_matching(X, imp_covariates, treatment_col, method='', use_caliper=use_caliper)\n",
    "        matched_indices = [idx for pair in matched_pairs for idx in pair]\n",
    "        X_matched_intermediate = X.loc[matched_indices].reset_index(drop=True)\n",
    "    else:\n",
    "        X_matched_intermediate = X.copy(deep=True)\n",
    "    # Matching Based on Propensity Scores\n",
    "    matched_pairs, X_ps = matching_propensity(X_matched_intermediate, all_vars, treatment_col, use_caliper=use_caliper)\n",
    "    matched_indices = [idx for pair in matched_pairs for idx in pair]\n",
    "    X_matched = X_ps.loc[matched_indices].reset_index(drop=True)\n",
    "    check_balance_after_matching(X_matched, all_vars)\n",
    "    return X_matched\n",
    "\n",
    "\n",
    "def perform_balancing_method3(X, imp_covariates, all_vars, use_caliper=True):\n",
    "    treatment_col = 'T'\n",
    "    # Matching Based on Propensity Scores\n",
    "    balances = check_balance_after_matching(X, all_vars)\n",
    "    # loop through a couple range 0 - 0.1 in interval 0.025\n",
    "    Ns = [1, 2, 3, 4]\n",
    "    Ns = [4]\n",
    "    for N in Ns:\n",
    "        threshs = [0, 0.025, 0.05, 0.075, 0.1]\n",
    "        threshs = [0]\n",
    "        thresh_dict = dict.fromkeys(threshs)\n",
    "        for thresh in threshs:\n",
    "            thresh_dict[thresh] = {}\n",
    "            balances_tuples = balances[balances > thresh]\n",
    "            unbalanced_covariates = list(balances_tuples.sort_values(ascending=False).index)\n",
    "            matched_pairs, X_ps = matching_propensity(X, unbalanced_covariates, treatment_col, N=N, use_caliper=use_caliper)\n",
    "            matched_indices = [idx for pair in matched_pairs for idx in pair]\n",
    "            X_matched = X_ps.loc[matched_indices].reset_index(drop=True)\n",
    "            new_balances = check_balance_after_matching(X_matched, all_vars)\n",
    "            new_balances_tuples = new_balances[new_balances > smd_threshold]\n",
    "            new_unbalanced_covariates = list(new_balances_tuples.sort_values(ascending=False).index)\n",
    "            thresh_dict[thresh]['data'] = X_matched\n",
    "            thresh_dict[thresh]['unbalanced_covars'] = new_unbalanced_covariates\n",
    "            if len(new_unbalanced_covariates) == 0:\n",
    "                print(f\"Using Threshold of {thresh}, Using N of {N}\")\n",
    "                return X_matched\n",
    "                break\n",
    "    min_key, items = min(thresh_dict.items(), key=lambda x: len(x[1]['unbalanced_covars']))\n",
    "    print(f\"Using Threshold of {min_key}, Using N of {N}\")\n",
    "    return items['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30f2670d",
   "metadata": {},
   "source": [
    "#### eICU Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steriods_eicu = pd.read_csv(\"data/eICU/steroids.csv\")\n",
    "df_steriods_eicu['patientunitstayid'] = df_steriods_eicu['patientunitstayid'].astype(int)\n",
    "df_features_eicu = pd.read_csv(\"data/eICU/feature.csv\")\n",
    "df_patient_eicu = pd.read_csv(\"data/eICU/eicu-database-2.0/patient.csv\")\n",
    "df_sepsis_eicu = pd.read_csv(\"data/eICU/sepsis.csv\")\n",
    "\n",
    "df_comorb_eicu = pd.read_csv(\"data/eICU/patient_comorbidity_score_df.csv\")\n",
    "df_sofa_eicu = pd.read_csv(\"data/eICU/eICU_sofa.csv\")\n",
    "df_sofa_comps_eicu = pd.read_csv(\"data/eICU/eICU_SOFA_score_comps.csv\")\n",
    "\n",
    "df_features_eicu = pd.merge(df_features_eicu, df_comorb_eicu[['patientunitstayid', 'comorbidity_score']], on='patientunitstayid',\n",
    "                       how='left')\n",
    "df_features_eicu = pd.merge(df_features_eicu, df_sofa_eicu[['patientunitstayid', 'sofa']], on='patientunitstayid',\n",
    "                       how='left')\n",
    "df_features_eicu = pd.merge(df_features_eicu, df_sofa_comps_eicu, on='patientunitstayid',\n",
    "                       how='left')\n",
    "sofa_comps = ['Respiration_score', 'Cardiovascular_score', 'CNS_score', 'Liver_score', 'Coagulation_score', 'Renal_score']\n",
    "df_features_eicu[sofa_comps] = df_features_eicu[sofa_comps].fillna(0)\n",
    "df_features_eicu['sofa'] = df_features_eicu['Respiration_score'] + \\\n",
    "                            df_features_eicu['Coagulation_score'] + \\\n",
    "                            df_features_eicu['Liver_score'] + \\\n",
    "                            df_features_eicu['Cardiovascular_score'] + \\\n",
    "                            df_features_eicu['CNS_score'] + \\\n",
    "                            df_features_eicu['Renal_score']\n",
    "\n",
    "df_ventilation_eicu = pd.read_csv(\"data/eICU/sepsis_ventilation.csv\")\n",
    "old_cols = [f'time_{i}' for i in range(0,29)]\n",
    "df_ventilation_eicu = df_ventilation_eicu[['patientunitstayid'] + old_cols]\n",
    "new_cols = ['patientunitstayid'] + [f'Vent_day_{i}' for i in range(0,29)]\n",
    "df_ventilation_eicu.columns = new_cols\n",
    "eligible_ventilation_patients_eicu = df_ventilation_eicu[df_ventilation_eicu['Vent_day_0'] == 1]['patientunitstayid'].values\n",
    "df_ventilation_eicu['patientunitstayid'] = df_ventilation_eicu['patientunitstayid'].astype(int)\n",
    "\n",
    "# read feature_bucket_with_filled_missing\n",
    "with open('data/eICU/ventilation_duration.json', 'r') as load_f:\n",
    "    ventilation_duration_data_eicu = json.load(load_f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e794e27",
   "metadata": {},
   "source": [
    "#### MIMIC Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steriods_mim = pd.read_csv(\"data/MIMIC/steroids.csv\")\n",
    "df_steriods_mim['patientunitstayid'] = df_steriods_mim['patientunitstayid'].astype(int)\n",
    "df_patient_mim = pd.read_csv(\"data/MIMIC/patient_info.csv\")\n",
    "df_patient_mim.rename(columns={'stay_id':'patientunitstayid'}, inplace=True)\n",
    "df_sepsis_mim = pd.read_csv(\"data/MIMIC/sepsis_sofa.csv\")\n",
    "df_sepsis_mim.rename(columns={'icustay_id':'patientunitstayid'}, inplace=True)\n",
    "\n",
    "df_comorb_mim = pd.read_csv(\"data/MIMIC/patient_comorbidity_score_df.csv\")\n",
    "df_sofa_comps_mim = pd.read_csv(\"data/MIMIC/sofa_score_comps.csv\")\n",
    "\n",
    "df_features_mim = pd.read_csv(\"data/MIMIC/features.csv\")\n",
    "df_comorb_mim = pd.merge(df_patient_mim[['subject_id', 'patientunitstayid']], df_comorb_mim, on='subject_id',\n",
    "                       how='left')\n",
    "df_features_mim = pd.merge(df_features_mim, df_comorb_mim[['patientunitstayid', 'comorbidity_score']], on='patientunitstayid',\n",
    "                       how='left')\n",
    "df_features_mim = pd.merge(df_features_mim, df_sofa_comps_mim, on='patientunitstayid',\n",
    "                       how='left')\n",
    "df_features_mim.rename(columns={'SOFA_score':'sofa'}, inplace=True)\n",
    "df_features_mim = pd.merge(df_features_mim, df_patient_mim[['patientunitstayid', 'gender', 'age']], on='patientunitstayid',\n",
    "                       how='left')\n",
    "sofa_comps = ['Respiration_score', 'Cardiovascular_score', 'CNS_score', 'Liver_score', 'Coagulation_score', 'Renal_score']\n",
    "df_features_mim[sofa_comps] = df_features_mim[sofa_comps].fillna(0)\n",
    "df_features_mim['sofa'] = df_features_mim['Respiration_score'] + \\\n",
    "                            df_features_mim['Coagulation_score'] + \\\n",
    "                            df_features_mim['Liver_score'] + \\\n",
    "                            df_features_mim['Cardiovascular_score'] + \\\n",
    "                            df_features_mim['CNS_score'] + \\\n",
    "                            df_features_mim['Renal_score']\n",
    "\n",
    "# Imputing Height and Weight\n",
    "imputer = IterativeImputer(random_state=100, max_iter=10)\n",
    "df_train = df_features_mim.loc[:, [\"Height\", \"Weight\"]]\n",
    "imputer.fit(df_train)\n",
    "df_imputed = imputer.transform(df_train)\n",
    "df_features_mim[['Height', 'Weight']] = df_imputed\n",
    "df_features_mim['Height'] = df_features_mim['Height'].apply(lambda x: x if x >= 48 else 48)\n",
    "# height is in inches, weight is in kg\n",
    "df_features_mim['BMI'] = ((df_features_mim['Weight'] * 2.20462) / (df_features_mim['Height']*df_features_mim['Height']) * 703).astype(int)\n",
    "max_days = 28\n",
    "\n",
    "# Making GCS Feature\n",
    "for i in range(1, max_days+1):\n",
    "    df_features_mim[f'GCS_day_{i}'] = df_features_mim[f'gcsVerbal_day_{i}'] + df_features_mim[f'gcsMotor_day_{i}'] + df_features_mim[f'gcsEye_day_{i}']\n",
    "\n",
    "df_ventilation_mim = pd.read_csv(\"data/MIMIC/ventilation_info.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13b8bb31",
   "metadata": {},
   "source": [
    "#### Eligibility Criteria Filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zx_subtypes_eicu = pd.read_csv(\"data/eICU/zxu_subtypes_lr_24h.csv\")\n",
    "df_zx_subtypes_mim = pd.read_csv(\"data/MIMIC/zxu_subtypes_lr_24h.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2209c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subcomponent Analysis\n",
    "sub_component_analysis = 0\n",
    "cv = 1\n",
    "resp = 0\n",
    "cns = 0\n",
    "liv = 0\n",
    "coag = 0\n",
    "rn = 0\n",
    "greater = 1\n",
    "lesser = not greater\n",
    "\n",
    "sepsis_zx_subtype = 'NONE'\n",
    "# options include NONE, 1, 3 (others too small)\n",
    "\n",
    "# Default Parameters to Stick to\n",
    "worst_case_mortality = 1\n",
    "treatment_strat_question = 1\n",
    "biological_question = not treatment_strat_question\n",
    "grace_period_hours = 0\n",
    "remove_event_before_grace = 0\n",
    "create_clones_before_grace_outcome = 1\n",
    "create_clones = grace_period_hours\n",
    "perform_censoring = 0 or (biological_question)\n",
    "remove_censored = 0\n",
    "include_extra_treated = 1\n",
    "remove_immortal_time_treated = 1\n",
    "remove_missing_feats = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d1325af",
   "metadata": {},
   "source": [
    "#### eICU Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45984b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_patients_eicu = df_sepsis_eicu[df_sepsis_eicu['sepsis_onset'] <= 1440]['patientunitstayid'].values\n",
    "\n",
    "# Get rid of patient with previous steriod usage to Day 0\n",
    "# Only if greater than 160\n",
    "steroid_dosage = 160\n",
    "df_st = df_steriods_eicu[df_steriods_eicu['day_0'] < steroid_dosage]\n",
    "\n",
    "# Get rid of patients without sepsis\n",
    "df_st = df_st[df_st['patientunitstayid'].isin(sepsis_patients_eicu)]\n",
    "\n",
    "# Getting Patients Who Were On Mechnical Ventilation at Baseline\n",
    "df_st = df_st[df_st['patientunitstayid'].isin(eligible_ventilation_patients_eicu)]\n",
    "\n",
    "df_censor = df_st.copy(deep=True)\n",
    "\n",
    "# Patient is treated if they have over 160 steriods within grace window from inclusion criteria\n",
    "grace_period_days = int(grace_period_hours/24.0)\n",
    "\n",
    "grace_days_consider = []\n",
    "for i in range(0, 2+grace_period_days):\n",
    "    grace_days_consider.append(f\"day_{i}\")\n",
    "\n",
    "if biological_question:\n",
    "    df_st_temp = df_st.copy(deep=True)\n",
    "    df_st_temp = df_st_temp.set_index('patientunitstayid')\n",
    "    df_st_temp['treatment_day']=df_st_temp.keys()[np.argmax(df_st_temp.values>=steroid_dosage,axis=1)]\n",
    "    patients_to_keep = df_st_temp['treatment_day'].isin(grace_days_consider)\n",
    "    df_st_temp = df_st_temp[patients_to_keep]\n",
    "    df_st = df_st[patients_to_keep.values]\n",
    "    df_censor = df_censor[patients_to_keep.values]\n",
    "elif treatment_strat_question:\n",
    "    df_st_temp = df_st.copy(deep=True)\n",
    "    df_st_temp = df_st_temp.set_index('patientunitstayid')\n",
    "    df_st_temp = df_st_temp[grace_days_consider]\n",
    "    df_st_temp['treatment_day']=df_st_temp.keys()[np.argmax(df_st_temp.values>=steroid_dosage,axis=1)]\n",
    "\n",
    "# If resultant is day_0, that means it is not eligible (no steroid > 160)\n",
    "df_st['T'] = (df_st_temp['treatment_day'] != 'day_0').values\n",
    "\n",
    "df_st['T'] = df_st['T'].astype(int)\n",
    "df_st['treatment_day'] = df_st_temp['treatment_day'].values\n",
    "df_censor['treatment_day'] = df_st_temp['treatment_day'].values\n",
    "\n",
    "no_censor_window = 3\n",
    "df_censor['window_days'] = df_censor['treatment_day'].apply(get_window_lists_adj, no_censor_window=no_censor_window)\n",
    "\n",
    "# Window where steriod admin is ok and if steriod admin after, patient is censored\n",
    "## Excluding last for coding purposes --> when deciding censoring, start at day after\n",
    "censor_days = []\n",
    "for i in df_censor['patientunitstayid'].values:\n",
    "    df_censor_temp = df_censor[df_censor['patientunitstayid'] == i]\n",
    "    window_days = df_censor_temp['window_days'].values[0]\n",
    "    treatment_day = df_censor_temp['treatment_day'].values[0]\n",
    "    df_censor_temp = df_censor_temp.drop(columns=window_days+['treatment_day', 'window_days', 'patientunitstayid'])\n",
    "    if df_censor_temp.size == 0:\n",
    "        censor_days.append(np.inf)\n",
    "        continue\n",
    "    else:\n",
    "        if np.sum(df_censor_temp.values>=steroid_dosage) == 0:\n",
    "            censor_days.append(np.inf)\n",
    "            continue\n",
    "        else:\n",
    "            censor_day = df_censor_temp.keys()[np.argmax(df_censor_temp.values>=steroid_dosage,axis=1)].values[0]\n",
    "    treated = df_st[df_st['patientunitstayid'] == i]['T'].values[0]\n",
    "    censor_days.append(censor_day)\n",
    "\n",
    "df_censor['censor'] = censor_days\n",
    "df_censor = df_censor.reset_index(drop=True)\n",
    "df_censor = df_censor[['patientunitstayid', 'censor']].reset_index(drop=True)\n",
    "\n",
    "df_st = pd.merge(df_st, df_censor, on='patientunitstayid')\n",
    "\n",
    "# Getting Mortality Information\n",
    "df_pat = df_patient_eicu[['patientunitstayid', 'hospitaldischargestatus', 'hospitaldischargeoffset', 'hospitaldischargelocation']]\n",
    "df_pat = df_pat.dropna(subset=['patientunitstayid', 'hospitaldischargestatus', 'hospitaldischargeoffset'])\n",
    "df_pat['hospitaldischargelocation'].fillna(value='Other', inplace=True)\n",
    "df_pat['hospitaldischargestatus'] = df_pat['hospitaldischargestatus'].astype('category').cat.codes\n",
    "df_pat['duration_day'] = df_pat['hospitaldischargeoffset'] / (60 * 24.0)\n",
    "\n",
    "# # Do we treat people who died after 28 days as alive? And set duration to 28 days?\n",
    "df_pat.loc[df_pat['duration_day'] >= 28, 'hospitaldischargestatus'] = 0\n",
    "df_pat.loc[df_pat['duration_day'] >= 28, 'duration_day'] = 28\n",
    "df_pat = df_pat[df_pat['duration_day'] >= 0]\n",
    "\n",
    "if remove_event_before_grace:\n",
    "    str_day = grace_days_consider[-1]\n",
    "    day = get_day(str_day)\n",
    "    df_pat = df_pat[df_pat['duration_day'] >= day]\n",
    "\n",
    "df_st_pat = pd.merge(df_st, df_pat, on='patientunitstayid')\n",
    "df_st_pat['treatment_day'] = df_st_pat['treatment_day'].apply(get_day)\n",
    "df_st_pat['censor'] = df_st_pat['censor'].apply(get_day)\n",
    "\n",
    "if create_clones_before_grace_outcome:\n",
    "    temp = df_st_pat[df_st_pat['duration_day'] < get_day(grace_days_consider[-1])]\n",
    "    # Make treated clones\n",
    "    df_untreated_to_treated = temp[temp['T'] == 0]\n",
    "    df_untreated_to_treated['T'] = 1\n",
    "    df_untreated_to_treated['treatment_day'] = 1\n",
    "    # df_untreated_to_treated['hospitaldischargestatus'] = 0 # censor these patients?\n",
    "    # Make untreated clones\n",
    "    df_treated_to_untreated = temp[temp['T'] == 1]\n",
    "    df_treated_to_untreated['T'] = 0\n",
    "    df_treated_to_untreated['treatment_day'] = 0\n",
    "    # df_treated_to_untreated['hospitaldischargestatus'] = 0 # censor these patients?\n",
    "    df_st_pat = pd.concat([df_st_pat, df_untreated_to_treated, df_treated_to_untreated]).reset_index(drop=True)\n",
    "\n",
    "# Figure out real duration with Day 0 based on treatment (steroid > 160)\n",
    "df_st_pat['temp_treatment_day'] = 0\n",
    "df_st_pat.loc[df_st_pat['treatment_day'] >= 1, 'temp_treatment_day'] = df_st_pat['treatment_day'] - 1\n",
    "df_st_pat['duration_real'] = df_st_pat['duration_day'] - df_st_pat['temp_treatment_day'] \n",
    "# Figure out duration if censoring for each patient\n",
    "df_st_pat['duration_censor'] = df_st_pat['censor'] - df_st_pat['treatment_day']\n",
    "# Some patients die on the day they are treated - treat their duration as 0\n",
    "df_st_pat[(df_st_pat['duration_real'] < 0) & (df_st_pat['duration_real'] > -1)] = 0\n",
    "# Small number of patients have duration much smaller than treatment - weird samples\n",
    "df_st_pat = df_st_pat[df_st_pat['duration_real'] > 0]\n",
    "\n",
    "if perform_censoring:\n",
    "    # Account for censoring in duration\n",
    "    df_st_pat['duration_final'] = df_st_pat[['duration_censor','duration_real']].min(axis=1)\n",
    "elif remove_censored:\n",
    "    # Remove patients who were censored due to retreatment\n",
    "    df_st_pat['duration_censor'] = df_st_pat['duration_censor'].replace(np.inf, 1000)\n",
    "    df_st_pat = df_st_pat[df_st_pat.duration_real <= df_st_pat.duration_censor]\n",
    "    df_st_pat['duration_final'] = df_st_pat['duration_real']\n",
    "else:\n",
    "    # Do not Account for censoring in duration\n",
    "    df_st_pat['duration_final'] = df_st_pat['duration_real']\n",
    "\n",
    "df_temp = df_st_pat.copy(deep=True)\n",
    "df_st_pat = df_st_pat[['patientunitstayid', 'T', 'hospitaldischargestatus', 'hospitaldischargelocation', 'duration_final', 'duration_real', 'duration_day', 'duration_censor', 'treatment_day']]\n",
    "df_st_pat = df_st_pat.reset_index(drop=True)\n",
    "\n",
    "# Get Day of Ventilation Cessation\n",
    "# To note, ventilation information seems to be missing as many patients don't have data before date of death\n",
    "df_ventilation_eligible = df_ventilation_eicu[df_ventilation_eicu['patientunitstayid'].isin(df_st['patientunitstayid'].values)]\n",
    "df_ventilation_eligible = df_ventilation_eligible.sort_values(by=['patientunitstayid']).reset_index(drop=True)\n",
    "\n",
    "df_ventilation_info = pd.DataFrame(data=df_ventilation_eligible['patientunitstayid'].values,\n",
    "                                   columns=['patientunitstayid'])\n",
    "df_ventilation_info['last_val'] = df_ventilation_eligible.ffill(axis=1).iloc[:, -1]\n",
    "def get_last_nonnan_col(row):\n",
    "    last_nonnan_col = row.last_valid_index()\n",
    "    day = int(last_nonnan_col[last_nonnan_col.rfind('_')+1:])\n",
    "    return day\n",
    "df_ventilation_info['last_ventilation_measurment_day'] = df_ventilation_eligible.apply(get_last_nonnan_col, axis=1)\n",
    "\n",
    "# Assign Patients Who Have last_ventilation_measurment_day = 0 to =1\n",
    "df_ventilation_info.loc[df_ventilation_info['last_ventilation_measurment_day'] == 0, 'last_ventilation_measurment_day']=1\n",
    "\n",
    "# Pulling ventilation duration from JSON File\n",
    "pats = df_ventilation_info['patientunitstayid'].values\n",
    "total_duration = []\n",
    "for pat in pats:\n",
    "    try:\n",
    "        duration = ventilation_duration_data_eicu[str(pat)]['end'][-1] / 1440\n",
    "    except:\n",
    "        duration = None\n",
    "    total_duration.append(duration)\n",
    "total_duration = np.array(total_duration)\n",
    "total_duration[total_duration > 28] = 28\n",
    "df_ventilation_info['exact_ventilation_duration'] = total_duration\n",
    "\n",
    "# Other Categories are censored (set to 0 at duration)\n",
    "# Mortality events are extended to worst case\n",
    "\n",
    "df_st_pat['hospitaldischargelocation_coded'] =  df_st_pat[\"hospitaldischargelocation\"].map({'Other External':0,\n",
    "                                        'Other Hospital':0, 'Skilled Nursing Facility':1,\n",
    "                                           'Home':1, 'Rehabilitation':1, 'Death':0,\n",
    "                                                    'Nursing Home':1, 'Other':0})\n",
    "\n",
    "# Worst-Outcome Censoring for those that have ICU mortality\n",
    "df_st_pat.loc[df_st_pat[\"hospitaldischargestatus\"] == 1, \"duration_final\"] = 28\n",
    "\n",
    "df_st_pat = pd.merge(df_st_pat, df_ventilation_info, on=['patientunitstayid'])\n",
    "df_st_pat['ventilation_status'] = 0\n",
    "\n",
    "# Loss to Follow Up (last_ventilation_measurment_day < duration_final) are censored at last_ventilation_measurment_day\n",
    "df_st_pat['exact_ventilation_duration'] = df_st_pat[['duration_real', 'exact_ventilation_duration']].min(axis=1)\n",
    "df_st_pat['duration_final_rounded'] = df_st_pat['duration_real'].astype(int)\n",
    "df_st_pat['ventilation_duration'] = df_st_pat['exact_ventilation_duration'].astype(int)\n",
    "\n",
    "# Accounting for death as a competing event, if death on day of last_ventilation_measurment_day\n",
    "df_st_pat.loc[(df_st_pat['ventilation_duration'] == df_st_pat['duration_final_rounded']) &\n",
    "             (df_st_pat['hospitaldischargestatus'] == 1), 'ventilation_duration'] = 28\n",
    "\n",
    "# If discharged to a better location on day of last_ventilation_measurment_day, set status to 1\n",
    "df_st_pat.loc[(df_st_pat['ventilation_duration'] == df_st_pat['duration_final_rounded']) &\n",
    "             (df_st_pat['hospitaldischargelocation_coded'] == 1), 'ventilation_status'] = 1\n",
    "\n",
    "# For those that cease ventilation, set ventilation status to 1\n",
    "df_st_pat.loc[(df_st_pat['ventilation_duration'] < df_st_pat['duration_final_rounded']), 'ventilation_status'] = 1\n",
    "\n",
    "if sub_component_analysis:\n",
    "    df_st_pat = pd.merge(df_st_pat, df_sofa_comps_eicu, on='patientunitstayid')\n",
    "    if cv:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Cardiovascular_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Cardiovascular_score'] < 2]\n",
    "    elif resp:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Respiration_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Respiration_score'] < 2]\n",
    "    elif cns:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['CNS_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['CNS_score'] < 2]\n",
    "    elif liv:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Liver_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Liver_score'] < 2]\n",
    "    elif coag:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Coagulation_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Coagulation_score'] < 2]\n",
    "    elif rn:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Renal_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Renal_score'] < 2]\n",
    "    df_st_pat = df_st_pat.drop(columns=['Cardiovascular_score', 'Respiration_score', 'CNS_score', 'Liver_score', 'Coagulation_score', 'Renal_score'])\n",
    "    \n",
    "try:\n",
    "    zx_group = int(sepsis_zx_subtype)\n",
    "    subtype_patients = df_zx_subtypes_eicu[df_zx_subtypes_eicu['subtype'] == zx_group]['patientunitstayid'].values\n",
    "    df_st_pat = df_st_pat[df_st_pat['patientunitstayid'].isin(subtype_patients)]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_st_pat_eicu = df_st_pat.copy(deep=True)\n",
    "\n",
    "df_feat = df_features_eicu.copy(deep=True)\n",
    "df_feat = df_feat[df_feat['patientunitstayid'].isin(df_st_pat['patientunitstayid'].values)]\n",
    "feat_day_titles = [\"day_\" + str(i+1) for i in range(28)]\n",
    "\n",
    "# Drop Extremely Missing Features\n",
    "lymph_features = ['Lymphocyte_count_' + day_title for day_title in feat_day_titles]\n",
    "df_feat.drop(columns=lymph_features, inplace=True)\n",
    "time_feature_names = ['Albumin', 'ALT', 'AST', 'Bands', 'Bicarbonate', 'Bilirubin',\n",
    "                 'BUN','Chloride', 'Creatinine', 'CRP', 'FiO2', 'GCS', 'Glucose', 'Heart_rate',\n",
    "                 'Hemoglobin', 'INR', 'Lactate', 'Lymphocyte_percent', 'MAP',\n",
    "                 'PaO2', 'Platelet', 'RDW', 'Respiratory_rate','SO2', 'Sodium','Systolic_ABP',\n",
    "                 'Temperature', 'Troponin I', 'Troponin T', 'Urine', 'WBC']\n",
    "baseline_feature_names = ['age', 'gender', 'BMI', 'comorbidity_score', 'sofa', 'Respiration_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score']\n",
    "\n",
    "# Missingness for Baseline Confounders\n",
    "imp_mean = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "df_feat.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "df_feat['gender'] = df_feat['gender'].fillna(\"Missing\")\n",
    "one_hot_gender = pd.get_dummies(df_feat['gender'])\n",
    "df_feat = df_feat.drop('gender',axis = 1)\n",
    "df_feat = df_feat.join(one_hot_gender)\n",
    "df_feat = df_feat.rename(columns={\"Female\": \"gender_Female\", \"Male\": \"gender_Male\",\n",
    "                                 \"Unknown\": \"gender_Unknown\"})\n",
    "if 'gender_Unknown' in df_feat:\n",
    "    df_feat['gender_Missing'] = df_feat['gender_Unknown']\n",
    "    df_feat.drop(columns=['gender_Unknown'], inplace=True)\n",
    "else:\n",
    "    df_feat['gender_Missing'] = 0\n",
    "\n",
    "num_vars = ['Albumin', 'ALT', 'AST', 'Bands', 'Bicarbonate',\n",
    "                     'Bilirubin', 'BUN', 'Chloride', 'Creatinine', 'CRP',\n",
    "                     'FiO2', 'GCS', 'Glucose', 'Heart_rate', 'Hemoglobin',\n",
    "                     'INR', 'Lactate', 'Lymphocyte_percent', 'MAP', 'PaO2',\n",
    "                     'Platelet', 'RDW', 'Respiratory_rate', 'SO2', 'Sodium',\n",
    "                     'Systolic_ABP', 'Temperature', 'Troponin I', 'Troponin T',\n",
    "                     'Urine', 'WBC']\n",
    "num_feats = ['age', 'BMI']\n",
    "for i in range(0, 28):\n",
    "    for var in num_vars:\n",
    "        num_feats.append(f\"{var}_day_{i+1}\")\n",
    "df_feat[num_feats] = clean_outliers(df_feat[num_feats])\n",
    "df_feat['age_missing'] = df_feat['age'].isnull().astype(int)\n",
    "df_feat['BMI_missing'] = df_feat['BMI'].isnull().astype(int)\n",
    "df_feat['age'] = imp_mean.fit_transform(df_feat['age'].values.reshape(-1,1))[:,0]\n",
    "df_feat['BMI'] = imp_mean.fit_transform(df_feat['BMI'].values.reshape(-1,1))[:,0]\n",
    "df_feat['sofa'] = imp_mean.fit_transform(df_feat['sofa'].values.reshape(-1,1))[:,0]\n",
    "\n",
    "# Quantizing BMI\n",
    "df_feat['BMI_quant'] = df_feat['BMI'].apply(quantize_bmi)\n",
    "df_feat['BMI_orig'] = df_feat['BMI']\n",
    "df_feat['BMI'] = df_feat['BMI_quant']\n",
    "\n",
    "# Quantizing Age\n",
    "df_feat['age_quant'], age_bins = pd.qcut(df_feat['age'], 5, labels=[0,1,2,3,4], retbins=True, precision=3, duplicates='raise')\n",
    "df_feat['age_orig'] = df_feat['age']\n",
    "df_feat['age'] = df_feat['age_quant']\n",
    "imp_median = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "df_feat['age'] = df_feat['age'].astype(float)\n",
    "df_feat['age'] = imp_median.fit_transform(df_feat['age'].values.reshape(-1,1))\n",
    "df_feat['age'] = df_feat['age'].astype(int)\n",
    "\n",
    "# Missingness for Time Varying Covariates\n",
    "for tv_feature in time_feature_names:\n",
    "    tv_feature_all = [tv_feature + '_' + day_title for day_title in feat_day_titles]\n",
    "    df_feat[tv_feature_all] = clean_outliers(df_feat[tv_feature_all])\n",
    "    df_feat[tv_feature_all] = df_feat[tv_feature_all].ffill(axis = 1)\n",
    "    df_feat[tv_feature_all] = imp_mean.fit_transform(df_feat[tv_feature_all])\n",
    "\n",
    "# Point Treatments (Get Day of Treatment for Treated) \n",
    "df_confounder_list = []\n",
    "base_features = ['age', 'gender_Male', 'gender_Missing', 'BMI', 'age_missing',\n",
    "                 'BMI_missing', 'comorbidity_score', 'sofa', 'Respiration_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score']\n",
    "col_titles = ['patientunitstayid'] + time_feature_names + base_features\n",
    "\n",
    "\n",
    "for pat, T in zip(df_st_pat['patientunitstayid'].values, df_st_pat['T'].values):\n",
    "    treatment_day = df_st_pat[(df_st_pat['patientunitstayid'] == pat) & (df_st_pat['T'] == T)]['treatment_day'].values[0]\n",
    "    if treatment_day == 0:\n",
    "        treatment_day = 1\n",
    "    tv_point_features = [feat + '_day_' + str(treatment_day) for feat in time_feature_names]\n",
    "    confounders =  tv_point_features + base_features\n",
    "    df_feat_temp = df_feat[df_feat['patientunitstayid'] == pat]\n",
    "    df_feat_temp = df_feat_temp[['patientunitstayid'] + confounders].reset_index(drop=True)\n",
    "    df_feat_temp.columns = col_titles\n",
    "    df_feat_temp['T'] = T\n",
    "    df_confounder_list.append(df_feat_temp)\n",
    "    \n",
    "df_confounders_eicu = pd.concat(df_confounder_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e00deeec",
   "metadata": {},
   "source": [
    "#### MIMIC Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42870295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sepsis_patients_mim = df_sepsis_mim[df_sepsis_mim['hour_24'] >= 2]['patientunitstayid'].values\n",
    "\n",
    "# Get rid of patient with previous steriod usage to Day 0\n",
    "# Only if greater than 160\n",
    "steroid_dosage = 160\n",
    "df_st = df_steriods_mim[df_steriods_mim['day_-1'] < steroid_dosage]\n",
    "\n",
    "# Get rid of patients without sepsis\n",
    "df_st = df_st[df_st['patientunitstayid'].isin(sepsis_patients_mim)]\n",
    "df_st_follow_time = df_st[['patientunitstayid', 'follow-up-time']]\n",
    "df_st = df_st.drop(columns=['follow-up-time'])\n",
    "\n",
    "df_censor = df_st.copy(deep=True)\n",
    "\n",
    "# Patient is treated if they have over 160 steriods within grace window from inclusion criteria\n",
    "grace_period_days = int(grace_period_hours/24.0)\n",
    "\n",
    "grace_days_consider = []\n",
    "for i in range(0, 2+grace_period_days):\n",
    "    grace_days_consider.append(f\"day_{i}\")\n",
    "\n",
    "if biological_question:\n",
    "    df_st_temp = df_st.copy(deep=True)\n",
    "    df_st_temp = df_st_temp.set_index('patientunitstayid')\n",
    "    df_st_temp['treatment_day']=df_st_temp.keys()[np.argmax(df_st_temp.values>=steroid_dosage,axis=1)]\n",
    "    patients_to_keep = df_st_temp['treatment_day'].isin(grace_days_consider)\n",
    "    df_st_temp = df_st_temp[patients_to_keep]\n",
    "    df_st = df_st[patients_to_keep.values]\n",
    "    df_censor = df_censor[patients_to_keep.values]\n",
    "elif treatment_strat_question:\n",
    "    df_st_temp = df_st.copy(deep=True)\n",
    "    df_st_temp = df_st_temp.set_index('patientunitstayid')\n",
    "    df_st_temp = df_st_temp[grace_days_consider]\n",
    "    df_st_temp['treatment_day']=df_st_temp.keys()[np.argmax(df_st_temp.values>=steroid_dosage,axis=1)]\n",
    "\n",
    "# If resultant is day_0, that means it is not eligible (no steroid > 160)\n",
    "df_st['T'] = (df_st_temp['treatment_day'] != 'day_0').values\n",
    "\n",
    "df_st['T'] = df_st['T'].astype(int)\n",
    "df_st['treatment_day'] = df_st_temp['treatment_day'].values\n",
    "df_censor['treatment_day'] = df_st_temp['treatment_day'].values\n",
    "\n",
    "no_censor_window = 3\n",
    "df_censor['window_days'] = df_censor['treatment_day'].apply(get_window_lists_adj, no_censor_window=no_censor_window)\n",
    "\n",
    "# Window where steriod admin is ok and if steriod admin after, patient is censored\n",
    "## Excluding last for coding purposes --> when deciding censoring, start at day after\n",
    "censor_days = []\n",
    "for i in df_censor['patientunitstayid'].values:\n",
    "    df_censor_temp = df_censor[df_censor['patientunitstayid'] == i]\n",
    "    window_days = df_censor_temp['window_days'].values[0]\n",
    "    treatment_day = df_censor_temp['treatment_day'].values[0]\n",
    "    df_censor_temp = df_censor_temp.drop(columns=window_days+['treatment_day', 'window_days', 'patientunitstayid'])\n",
    "    if df_censor_temp.size == 0:\n",
    "        censor_days.append(np.inf)\n",
    "        continue\n",
    "    else:\n",
    "        if np.sum(df_censor_temp.values>=steroid_dosage) == 0:\n",
    "            censor_days.append(np.inf)\n",
    "            continue\n",
    "        else:\n",
    "            censor_day = df_censor_temp.keys()[np.argmax(df_censor_temp.values>=steroid_dosage,axis=1)].values[0]\n",
    "    treated = df_st[df_st['patientunitstayid'] == i]['T'].values[0]\n",
    "    censor_days.append(censor_day)\n",
    "\n",
    "df_censor['censor'] = censor_days\n",
    "df_censor = df_censor.reset_index(drop=True)\n",
    "df_censor = df_censor[['patientunitstayid', 'censor']].reset_index(drop=True)\n",
    "\n",
    "df_st = pd.merge(df_st, df_censor, on='patientunitstayid')\n",
    "\n",
    "# Getting Mortality Information\n",
    "df_pat = df_patient_mim[['patientunitstayid', 'hospitaldischargeoffset', 'hospitaldischargelocation']]\n",
    "df_pat = df_pat.dropna(subset=['patientunitstayid', 'hospitaldischargelocation', 'hospitaldischargeoffset'])\n",
    "df_pat['hospitaldischargestatus'] = df_pat['hospitaldischargelocation'].apply(get_status)\n",
    "df_pat['duration_day'] = df_pat['hospitaldischargeoffset']\n",
    "\n",
    "# # Do we treat people who died after 28 days as alive? And set duration to 28 days?\n",
    "df_pat.loc[df_pat['duration_day'] >= 28, 'hospitaldischargestatus'] = 0\n",
    "df_pat.loc[df_pat['duration_day'] >= 28, 'duration_day'] = 28\n",
    "df_pat = df_pat[df_pat['duration_day'] >= 0]\n",
    "\n",
    "if remove_event_before_grace:\n",
    "    str_day = grace_days_consider[-1]\n",
    "    day = get_day(str_day)\n",
    "    df_pat = df_pat[df_pat['duration_day'] >= day]\n",
    "\n",
    "df_st_pat = pd.merge(df_st, df_pat, on='patientunitstayid')\n",
    "df_st_pat['treatment_day'] = df_st_pat['treatment_day'].apply(get_day)\n",
    "df_st_pat['censor'] = df_st_pat['censor'].apply(get_day)\n",
    "\n",
    "if create_clones_before_grace_outcome:\n",
    "    temp = df_st_pat[df_st_pat['duration_day'] < get_day(grace_days_consider[-1])]\n",
    "    # Make treated clones\n",
    "    df_untreated_to_treated = temp[temp['T'] == 0]\n",
    "    df_untreated_to_treated['T'] = 1\n",
    "    df_untreated_to_treated['treatment_day'] = 1\n",
    "    # df_untreated_to_treated['hospitaldischargestatus'] = 0 # censor these patients?\n",
    "    # Make untreated clones\n",
    "    df_treated_to_untreated = temp[temp['T'] == 1]\n",
    "    df_treated_to_untreated['T'] = 0\n",
    "    df_treated_to_untreated['treatment_day'] = 0\n",
    "    # df_treated_to_untreated['hospitaldischargestatus'] = 0 # censor these patients?\n",
    "    df_st_pat = pd.concat([df_st_pat, df_untreated_to_treated, df_treated_to_untreated]).reset_index(drop=True)\n",
    "\n",
    "if remove_immortal_time_treated:\n",
    "    df_st_pat = pd.merge(df_st_pat, df_st_follow_time, on='patientunitstayid')\n",
    "    df_st_pat.loc[df_st_pat['T'] == 0, 'follow-up-time'] = 0\n",
    "    df_st_pat['follow-up-time'] = df_st_pat['follow-up-time'] / 1440\n",
    "    df_st_pat['duration_day'] = df_st_pat['duration_day'] - df_st_pat['follow-up-time']\n",
    "    df_st_pat = df_st_pat[df_st_pat['duration_day'] > 0]\n",
    "\n",
    "# Figure out real duration with Day 0 based on treatment (steroid > 160)\n",
    "df_st_pat['temp_treatment_day'] = 0\n",
    "df_st_pat.loc[df_st_pat['treatment_day'] >= 1, 'temp_treatment_day'] = df_st_pat['treatment_day'] - 1\n",
    "df_st_pat['duration_real'] = df_st_pat['duration_day'] - df_st_pat['temp_treatment_day'] \n",
    "# Figure out duration if censoring for each patient\n",
    "df_st_pat['duration_censor'] = df_st_pat['censor'] - df_st_pat['treatment_day']\n",
    "# Some patients die on the day they are treated - treat their duration as 0\n",
    "df_st_pat[(df_st_pat['duration_real'] < 0) & (df_st_pat['duration_real'] > -1)] = 0\n",
    "# Small number of patients have duration much smaller than treatment - weird samples\n",
    "df_st_pat = df_st_pat[df_st_pat['duration_real'] > 0]\n",
    "\n",
    "if perform_censoring:\n",
    "    # Account for censoring in duration\n",
    "    df_st_pat['duration_final'] = df_st_pat[['duration_censor','duration_real']].min(axis=1)\n",
    "elif remove_censored:\n",
    "    # Remove patients who were censored due to retreatment\n",
    "    df_st_pat['duration_censor'] = df_st_pat['duration_censor'].replace(np.inf, 1000)\n",
    "    df_st_pat = df_st_pat[df_st_pat.duration_real <= df_st_pat.duration_censor]\n",
    "    df_st_pat['duration_final'] = df_st_pat['duration_real']\n",
    "else:\n",
    "    # Do not Account for censoring in duration\n",
    "    df_st_pat['duration_final'] = df_st_pat['duration_real']\n",
    "\n",
    "df_temp = df_st_pat.copy(deep=True)\n",
    "df_st_pat = df_st_pat[['patientunitstayid', 'T', 'hospitaldischargestatus', 'hospitaldischargelocation', 'duration_final', 'duration_real', 'duration_day', 'duration_censor', 'treatment_day']]\n",
    "df_st_pat = df_st_pat.reset_index(drop=True)\n",
    "\n",
    "# Getting outcomes for menchanical ventilation\n",
    "df_ventilation_mim.rename(columns={'stay_id':'patientunitstayid'}, inplace=True)\n",
    "duplicate_mask = df_ventilation_mim.duplicated(subset='patientunitstayid', keep=False)\n",
    "duplicate_rows = df_ventilation_mim[duplicate_mask]\n",
    "unique_rows = df_ventilation_mim[~duplicate_mask]\n",
    "\n",
    "# Combining Certain Patients data\n",
    "unique_pats_in_dup = pd.unique(duplicate_rows['patientunitstayid'])\n",
    "new_patient_info = []\n",
    "for pat in unique_pats_in_dup:\n",
    "    pat_rows = duplicate_rows[duplicate_rows['patientunitstayid'] == pat] \n",
    "    day_start = pat_rows['day_start'].values[0]\n",
    "    total_time_used = np.sum(pat_rows['time_used_days'].values)\n",
    "    subject_id = pat_rows['subject_id'].values[0]\n",
    "    ham_id = pat_rows['hadm_id'].values[0]\n",
    "    new_patient_info.append([subject_id, ham_id, pat, day_start, total_time_used])\n",
    "new_df = pd.DataFrame(data=new_patient_info, columns=list(duplicate_rows))\n",
    "df_ventilation_edit = pd.concat([unique_rows, new_df])\n",
    "df_st_pat = pd.merge(df_st_pat, df_ventilation_edit[['patientunitstayid', 'day_start', 'time_used_days']], on=['patientunitstayid'])\n",
    "\n",
    "# Filtering patients to only patients who have ventilation at baseline\n",
    "df_st_pat = df_st_pat[df_st_pat['day_start'] == 1]\n",
    "df_st_pat['ventilation_status'] = 0\n",
    "df_st_pat['ventilation_duration'] = df_st_pat['time_used_days']\n",
    "# Accounting for death as a competing event, if death on day of last_ventilation_measurment_day\n",
    "df_st_pat.loc[(df_st_pat['hospitaldischargelocation'] == 'DIED'), 'ventilation_duration'] = 28\n",
    "# If discharged to a better location, set status to 1\n",
    "df_st_pat.loc[(df_st_pat['hospitaldischargelocation'] != 'DIED'), 'ventilation_status'] = 1\n",
    "df_st_pat['ventilation_duration'] = df_st_pat['ventilation_duration'].clip(upper=28)\n",
    "    \n",
    "if sub_component_analysis:\n",
    "    df_st_pat = pd.merge(df_st_pat, df_sofa_comps_mim, on='patientunitstayid')\n",
    "    if cv:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Cardiovascular_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Cardiovascular_score'] < 2]\n",
    "    elif resp:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Respiration_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Respiration_score'] < 2]\n",
    "    elif cns:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['CNS_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['CNS_score'] < 2]\n",
    "    elif liv:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Liver_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Liver_score'] < 2]\n",
    "    elif coag:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Coagulation_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Coagulation_score'] < 2]\n",
    "    elif rn:\n",
    "        if greater:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Renal_score'] >= 2]\n",
    "        else:\n",
    "            df_st_pat = df_st_pat[df_st_pat['Renal_score'] < 2]\n",
    "    df_st_pat = df_st_pat.drop(columns=['Cardiovascular_score', 'Respiration_score', 'CNS_score', 'Liver_score', 'Coagulation_score', 'Renal_score'])\n",
    "    \n",
    "try:\n",
    "    zx_group = int(sepsis_zx_subtype)\n",
    "    subtype_patients = df_zx_subtypes_mim[df_zx_subtypes_mim['subtype'] == zx_group]['patientunitstayid'].values\n",
    "    df_st_pat = df_st_pat[df_st_pat['patientunitstayid'].isin(subtype_patients)]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "df_st_pat_mim = df_st_pat.copy(deep=True)\n",
    "\n",
    "df_feat = df_features_mim.copy(deep=True)\n",
    "feat_day_titles = [\"day_\" + str(i+1) for i in range(28)]\n",
    "\n",
    "# Drop Extremely Missing Features\n",
    "## Bicarbonate, CRP, GCS], [Lactate]\n",
    "time_feature_names = ['Albumin', 'ALT', 'AST', 'Bands', 'Bilirubin',\n",
    "                 'BUN','Chloride', 'Creatinine', 'FiO2', 'Glucose', 'Heart_rate',\n",
    "                 'Hemoglobin', 'INR', 'MAP', 'Lymphocyte_count', 'Lactate', 'GCS',\n",
    "                 'PaO2', 'Platelet', 'Respiratory_rate','SO2', 'Sodium','Systolic_ABP',\n",
    "                 'Temperature', 'Troponin T', 'Urine', 'WBC']\n",
    "baseline_feature_names = ['age', 'gender', 'BMI', 'sofa', 'Respiration_score', 'comorbidity_score'\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score']\n",
    "\n",
    "# Missingness for Baseline Confounders\n",
    "imp_mean = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "df_feat.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "df_feat['gender'] = df_feat['gender'].fillna(\"Missing\")\n",
    "one_hot_gender = pd.get_dummies(df_feat['gender'])\n",
    "df_feat = df_feat.drop('gender',axis = 1)\n",
    "df_feat = df_feat.join(one_hot_gender)\n",
    "df_feat = df_feat.rename(columns={\"Female\": \"gender_Female\", \"Male\": \"gender_Male\",\n",
    "                                 \"Unknown\": \"gender_Unknown\"})\n",
    "if 'gender_Unknown' in df_feat:\n",
    "    df_feat['gender_Missing'] = df_feat['gender_Unknown']\n",
    "    df_feat.drop(columns=['gender_Unknown'], inplace=True)\n",
    "else:\n",
    "    df_feat['gender_Missing'] = 0\n",
    "\n",
    "num_vars = ['Albumin', 'ALT', 'AST', 'Bands',\n",
    "                     'Bilirubin', 'BUN', 'Chloride', 'Creatinine',\n",
    "                     'FiO2', 'Glucose', 'Heart_rate', 'Hemoglobin',\n",
    "                     'INR', 'MAP', 'PaO2', 'Lymphocyte_count', 'Lactate', 'GCS',\n",
    "                     'Platelet', 'Respiratory_rate', 'SO2', 'Sodium',\n",
    "                     'Systolic_ABP', 'Temperature', 'Troponin T',\n",
    "                     'Urine', 'WBC']\n",
    "num_feats = ['age', 'BMI']\n",
    "for i in range(0, 28):\n",
    "    for var in num_vars:\n",
    "        num_feats.append(f\"{var}_day_{i+1}\")\n",
    "df_feat[num_feats] = clean_outliers(df_feat[num_feats])\n",
    "df_feat['age_missing'] = df_feat['age'].isnull().astype(int)\n",
    "df_feat['BMI_missing'] = df_feat['BMI'].isnull().astype(int)\n",
    "df_feat['age'] = imp_mean.fit_transform(df_feat['age'].values.reshape(-1,1))[:,0]\n",
    "df_feat['BMI'] = imp_mean.fit_transform(df_feat['BMI'].values.reshape(-1,1))[:,0]\n",
    "df_feat['sofa'] = imp_mean.fit_transform(df_feat['sofa'].values.reshape(-1,1))[:,0]\n",
    "\n",
    "# Quantizing BMI\n",
    "df_feat['BMI_quant'] = df_feat['BMI'].apply(quantize_bmi)\n",
    "df_feat['BMI_orig'] = df_feat['BMI']\n",
    "df_feat['BMI'] = df_feat['BMI_quant']\n",
    "\n",
    "# Quantizing Age\n",
    "df_feat['age_quant'] = pd.cut(df_feat['age'], bins=age_bins, labels=[0,1,2,3,4], include_lowest=True)\n",
    "df_feat['age_orig'] = df_feat['age']\n",
    "df_feat['age'] = df_feat['age_quant']\n",
    "imp_median = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "df_feat['age'] = df_feat['age'].astype(float)\n",
    "df_feat['age'] = imp_median.fit_transform(df_feat['age'].values.reshape(-1,1))\n",
    "df_feat['age'] = df_feat['age'].astype(int)\n",
    "\n",
    "# Missingness for Time Varying Covariates\n",
    "for tv_feature in time_feature_names:\n",
    "    tv_feature_all = [tv_feature + '_' + day_title for day_title in feat_day_titles]\n",
    "    df_feat[tv_feature_all] = clean_outliers(df_feat[tv_feature_all])\n",
    "    df_feat[tv_feature_all] = df_feat[tv_feature_all].ffill(axis = 1)\n",
    "    df_feat[tv_feature_all] = imp_mean.fit_transform(df_feat[tv_feature_all])\n",
    "    \n",
    "df_feat = df_feat[df_feat['patientunitstayid'].isin(df_st_pat['patientunitstayid'].values)]\n",
    "    \n",
    "# Point Treatments (Get Day of Treatment for Treated) \n",
    "df_confounder_list = []\n",
    "base_features = ['age', 'gender_Male', 'gender_Missing', 'BMI', 'age_missing',\n",
    "                 'BMI_missing', 'sofa', 'Respiration_score', 'comorbidity_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score']\n",
    "col_titles = ['patientunitstayid'] + time_feature_names + base_features\n",
    "\n",
    "\n",
    "for pat, T in zip(df_st_pat['patientunitstayid'].values, df_st_pat['T'].values):\n",
    "    treatment_day = df_st_pat[(df_st_pat['patientunitstayid'] == pat) & (df_st_pat['T'] == T)]['treatment_day'].values[0]\n",
    "    if treatment_day == 0:\n",
    "        treatment_day = 1\n",
    "    tv_point_features = [feat + '_day_' + str(treatment_day) for feat in time_feature_names]\n",
    "    confounders =  tv_point_features + base_features\n",
    "    df_feat_temp = df_feat[df_feat['patientunitstayid'] == pat]\n",
    "    df_feat_temp = df_feat_temp[['patientunitstayid'] + confounders].reset_index(drop=True)\n",
    "    df_feat_temp.columns = col_titles\n",
    "    df_feat_temp['T'] = T\n",
    "    df_confounder_list.append(df_feat_temp)\n",
    "    \n",
    "df_confounders_mim = pd.concat(df_confounder_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "112c50f0",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da6fad28",
   "metadata": {},
   "source": [
    "### Balancing Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b554a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eicu = pd.merge(df_confounders_eicu, df_st_pat_eicu, on=['patientunitstayid', 'T'])\n",
    "df_mim = pd.merge(df_confounders_mim, df_st_pat_mim, on=['patientunitstayid', 'T'])\n",
    "overlapping_columns = (list(set(list(df_mim)) & set(list(df_eicu))))\n",
    "overlapping_columns.insert(0, overlapping_columns.pop(overlapping_columns.index('patientunitstayid')))\n",
    "df_mim = df_mim[overlapping_columns]\n",
    "df_mim['dataset'] = 0\n",
    "df_eicu = df_eicu[overlapping_columns]\n",
    "df_eicu['dataset'] = 1\n",
    "df = pd.concat([df_mim, df_eicu])\n",
    "\n",
    "overlapping_columns.append('dataset')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "keep_certain_level_sofa = 0\n",
    "if keep_certain_level_sofa:\n",
    "    lower_level = 8\n",
    "    higher_level = 25\n",
    "    df = df[(df['sofa'] >= lower_level) & (df['sofa'] <= higher_level)].reset_index(drop=True)\n",
    "\n",
    "patient_id = ['patientunitstayid']\n",
    "misc_vars = ['T', 'hospitaldischargestatus', 'duration_final', 'duration_real',\n",
    "             'hospitaldischargelocation','ventilation_duration', 'ventilation_status']\n",
    "cat_vars = ['gender_Male', 'dataset']\n",
    "num_vars = ['Albumin', 'ALT', 'AST', 'Bands', 'Bicarbonate',\n",
    "                     'Bilirubin', 'BUN', 'Chloride', 'Creatinine', 'CRP',\n",
    "                     'FiO2', 'GCS', 'Glucose', 'Heart_rate', 'Hemoglobin',\n",
    "                     'INR', 'Lactate', 'Lymphocyte_percent', 'MAP', 'PaO2',\n",
    "                     'Platelet', 'RDW', 'Respiratory_rate', 'SO2', 'Sodium',\n",
    "                     'Systolic_ABP', 'Temperature', 'Troponin I', 'Troponin T',\n",
    "                     'Urine', 'WBC', 'comorbidity_score', 'sofa', 'Respiration_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score', 'age', 'BMI']\n",
    "discrete_vars = ['gender_Male', 'dataset']\n",
    "continuous_vars = ['Albumin', 'ALT', 'AST', 'Bands', 'Bicarbonate',\n",
    "                     'Bilirubin', 'BUN', 'Chloride', 'Creatinine', 'CRP',\n",
    "                     'FiO2', 'GCS', 'Glucose', 'Heart_rate', 'Hemoglobin',\n",
    "                     'INR', 'Lactate', 'Lymphocyte_percent', 'MAP', 'PaO2',\n",
    "                     'Platelet', 'RDW', 'Respiratory_rate', 'SO2', 'Sodium',\n",
    "                     'Systolic_ABP', 'Temperature', 'Troponin I', 'Troponin T',\n",
    "                     'Urine', 'WBC', 'comorbidity_score', 'age', 'Respiration_score',\n",
    "                         'Cardiovascular_score', 'CNS_score', 'Liver_score',\n",
    "                          'Coagulation_score', 'Renal_score', 'BMI']\n",
    "\n",
    "cat_vars = (list(set(list(cat_vars)) & set(list(overlapping_columns))))\n",
    "num_vars = (list(set(list(num_vars)) & set(list(overlapping_columns))))\n",
    "discrete_vars = (list(set(list(discrete_vars)) & set(list(overlapping_columns))))\n",
    "continuous_vars = (list(set(list(continuous_vars)) & set(list(overlapping_columns))))\n",
    "\n",
    "all_vars = num_vars + cat_vars\n",
    "\n",
    "# Remove colzumns with no differences in values across patients\n",
    "for col in all_vars:\n",
    "    if col == 'dataset':\n",
    "        continue\n",
    "    if (df[col] == df[col][0]).all():\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "        all_vars.remove(col)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[num_vars] = scaler.fit_transform(df[num_vars])\n",
    "X = df.drop(columns=['patientunitstayid', 'treatment_day'])\n",
    "# X = df.copy(deep=True)\n",
    "\n",
    "# Removing sofa from analysis bc we have components\n",
    "use_vars = copy.deepcopy(all_vars)\n",
    "use_vars.remove('sofa')\n",
    "\n",
    "if remove_missing_feats:\n",
    "    use_vars.remove('ALT')\n",
    "    use_vars.remove('AST')\n",
    "    use_vars.remove('Albumin')\n",
    "    use_vars.remove('Bands')\n",
    "    use_vars.remove('Troponin T')\n",
    "\n",
    "imp_covariates = []\n",
    "X_matched = perform_balancing_method3(X, imp_covariates, use_vars, use_caliper=True)\n",
    "X = X_matched.copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of Treated Patients: {X[X['T'] == 1].shape[0]}\")\n",
    "print(f\"Percent of Patients Who Ceased Ventilation: {X[X['ventilation_status'] == 1].shape[0] / X.shape[0]}\")\n",
    "\n",
    "balances = check_balance_after_matching(X, use_vars)\n",
    "print('Number of unbalanced covariates: ' + str((balances>smd_threshold).sum()))\n",
    "balances[balances > smd_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of propensity scores and weights\n",
    "treatment = X[X['T'] == 1]\n",
    "control = X[X['T'] == 0]\n",
    "\n",
    "plt.figure(figsize=(15, 6)) # Increase the width to better accommodate three subplots\n",
    "\n",
    "plt.subplot(1, 3, 1) # Change subplot layout to 1 row, 3 columns\n",
    "plt.hist(treatment['ps'], alpha=0.5, label='Treatment', density=True)\n",
    "plt.hist(control['ps'], alpha=0.5, label='Control', density=True)\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3) # Change subplot layout to 1 row, 3 columns\n",
    "other_var = 'Lactate'\n",
    "plt.hist(treatment[other_var], alpha=0.5, label='Treatment', density=True)\n",
    "plt.hist(control[other_var], alpha=0.5, label='Control', density=True)\n",
    "plt.xlabel(other_var)\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97093e39",
   "metadata": {},
   "source": [
    "#### Cumulative Incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['outcome'] =  X['ventilation_status']\n",
    "X_treated = X[X['T'] == 1]\n",
    "X_untreated = X[X['T'] == 0]\n",
    "\n",
    "print(f\"Naive 28 Day Cumulative Incidence for Treated: {X_treated[X_treated['outcome'] == 1].shape[0]/len(X_treated)}\")\n",
    "print(f\"Naive 28 Day Cumulative Incidence for Untreated: {X_untreated[X_untreated['outcome'] == 1].shape[0]/len(X_untreated)}\")\n",
    "print(f\"Percent of Patients Who Ceased Ventilation: {X[X['ventilation_status'] == 1].shape[0] / X.shape[0]}\")\n",
    "\n",
    "print(f\"Alive Length for Treated: {np.round(X_treated['ventilation_duration'].mean(), 2)}{np.round(X_treated['ventilation_duration'].std(), 2)}\")\n",
    "print(f\"Alive Length for Untreated: {np.round(X_untreated['ventilation_duration'].mean(), 2)}{np.round(X_untreated['ventilation_duration'].std(), 2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e67ed6",
   "metadata": {},
   "source": [
    "#### Cox Proportional Hazard Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df23cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cph = CoxPHFitter()\n",
    "features = use_vars + ['T', 'ventilation_duration', 'ventilation_status']\n",
    "\n",
    "data_cox = X[features]\n",
    "for col in list(data_cox):\n",
    "    if (data_cox[col] == data_cox[col][0]).all():\n",
    "        data_cox.drop(columns=[col], inplace=True)\n",
    "\n",
    "cph.fit(data_cox, duration_col='ventilation_duration', event_col='ventilation_status',\n",
    "        robust=True, fit_options={'step_size': 0.1})\n",
    "cph.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict median time to discharge for each treatment group\n",
    "med_time = cph.predict_median(data_cox)\n",
    "# Get difference in median time between the two treatment groups\n",
    "treated_indices = list(data_cox[data_cox['T'] == 1].index)\n",
    "untreated_indices = list(data_cox[data_cox['T'] == 0].index)\n",
    "diff = np.median(med_time.iloc[untreated_indices]) - np.median(med_time.iloc[treated_indices])\n",
    "print(f\"Difference in Median Time Between Groups: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6dac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d102f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "T = data_cox['ventilation_duration']\n",
    "E = data_cox['ventilation_status']\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "ax = plt.gca()  # Define the axis object here\n",
    "\n",
    "# fit the model for each treatment T and plot\n",
    "for name, grouped_df in data_cox.groupby('T'):\n",
    "    if name == 0:\n",
    "        label = 'Untreated'\n",
    "    else:\n",
    "        label = 'Treated'\n",
    "    kmf.fit(grouped_df['ventilation_duration'], grouped_df['ventilation_status'], label=label)\n",
    "    \n",
    "    # Transform the survival function and confidence intervals\n",
    "    transformed_sf = 1 - kmf.survival_function_\n",
    "    transformed_confidence = 1 - kmf.confidence_interval_\n",
    "    \n",
    "    # Plot the transformed survival function and confidence intervals\n",
    "    ax.plot(transformed_sf, label=label)\n",
    "    ax.fill_between(transformed_confidence.index, \n",
    "                    transformed_confidence.iloc[:, 0], \n",
    "                    transformed_confidence.iloc[:, 1], \n",
    "                    color=ax.lines[-1].get_color(), \n",
    "                    alpha=0.3)\n",
    "\n",
    "plt.xlabel('Days', fontsize=14)  # set x-axis label\n",
    "plt.ylabel('Probability of Ceasing Ventilation', fontsize=14)  # set y-axis label\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.ylim(-0.05, 1.05)  # set y-axis limits\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))  # set y-axis ticks\n",
    "\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
